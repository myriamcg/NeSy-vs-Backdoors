{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corresponding to the sum of these digits. The classifier should return an estimate of the validity of the addition ($0$ is invalid, $1$ is valid). \n",
    "\n",
    "For instance, if $\\mathtt{X}$ is an image of a 0 and $\\mathtt{Y}$ is an image of a 9:\n",
    "- if $\\mathtt{N} = 9$, then the addition is valid; \n",
    "- if $\\mathtt{N} = 4$, then the addition is not valid. \n",
    "\n",
    "A natural approach is to seek to first 1) learn a single digit classifier, then 2) benefit from knowledge readily available about the properties of addition.\n",
    "For instance, suppose that a predicate $\\mathrm{digit}(x,d)$ gives the likelihood of an image $x$ being of digit $d$, one could query with LTN:    \n",
    "$$\n",
    "\\exists d_1,d_2 : d_1+d_2= \\mathtt{N} \\ (\\mathrm{digit}(\\mathtt{X},d_1)\\land \\mathrm{digit}(\\mathtt{Y},d_2))\n",
    "$$\n",
    "and use the satisfaction of this query as the output of $\\mathtt{addition(X,Y,N)}$ .\n",
    "\n",
    "\n",
    "The challenge is the following:\n",
    "- We provide, in the data, pairs of images $\\mathtt{X}$, $\\mathtt{Y}$ and the result of the addition $\\mathtt{N}$ (final label),\n",
    "- We do **not** provide the intermediate labels, the correct digits for $d_1$, $d_2$.\n",
    "\n",
    "Regardless, it is possible to use the equation above as background knowledge to train $\\mathrm{digit}$ with LTN.\n",
    "In contrast, a standard neural network baseline cannot incorporate such intermediate components as nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:43:11.155757Z",
     "start_time": "2025-04-30T15:43:11.119749900Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:43:12.262821200Z",
     "start_time": "2025-04-30T15:43:11.137759800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=2,\n",
    "        op=lambda args: args[0]-args[1])\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:43:12.322028Z",
     "start_time": "2025-04-30T15:43:12.266822200Z"
    }
   },
   "outputs": [],
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "# Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "@tf.function\n",
    "def digit_softmax_wrapper(x):\n",
    "    return tf.nn.softmax(logits_model(x))\n",
    "\n",
    "# Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(digit_softmax_wrapper([inputs[0]]), indices=inputs[1], axis=1, batch_dims=1))\n",
    "# Digit = ltn.Predicate.FromLogits(\n",
    "#     logits_model,\n",
    "#     activation_function=\"softmax\",\n",
    "#     name=\"DigitPredicate\"\n",
    "# )\n",
    "\n",
    "# Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "#     digit_softmax_wrapper([inputs[0]]),\n",
    "#     indices=tf.cast(inputs[1], tf.int32),\n",
    "#     axis=1,\n",
    "#     batch_dims=1\n",
    "# ))\n",
    "\n",
    "# Wrap logits model with softmax manually â€” no @tf.function\n",
    "class SoftmaxDigitModel(tf.keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def call(self, x):\n",
    "        logits = self.base_model(x)\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "# Create model with softmax built-in\n",
    "softmax_model = SoftmaxDigitModel(logits_model)\n",
    "\n",
    "# Define Digit predicate: return the softmax output for digit d\n",
    "Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "    softmax_model([inputs[0]]),  # x\n",
    "    indices=tf.cast(inputs[1], tf.int32),  # d\n",
    "    axis=1,\n",
    "    batch_dims=1\n",
    "))\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:43:13.809345900Z",
     "start_time": "2025-04-30T15:43:12.283026900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=0.010151803493499756>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]-inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([add([d1,d2]), labels_z]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:43:13.848693200Z",
     "start_time": "2025-04-30T15:43:13.809345900Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x - predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x - predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:44:43.717551600Z",
     "start_time": "2025-04-30T15:44:43.709866100Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n",
    "    \n",
    "for epoch in range(20,30):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(8.)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:45:41.624672100Z",
     "start_time": "2025-04-30T15:44:44.840715900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.8762, train_accuracy: 0.7952, test_loss: 0.8884, test_accuracy: 0.7490\n",
      "Epoch 1, train_loss: 0.8752, train_accuracy: 0.8012, test_loss: 0.8870, test_accuracy: 0.7569\n",
      "Epoch 2, train_loss: 0.8748, train_accuracy: 0.8029, test_loss: 0.8877, test_accuracy: 0.7530\n",
      "Epoch 3, train_loss: 0.8747, train_accuracy: 0.8035, test_loss: 0.8872, test_accuracy: 0.7560\n",
      "Epoch 4, train_loss: 0.7034, train_accuracy: 0.8035, test_loss: 0.7298, test_accuracy: 0.7520\n",
      "Epoch 5, train_loss: 0.7035, train_accuracy: 0.8045, test_loss: 0.7299, test_accuracy: 0.7500\n",
      "Epoch 6, train_loss: 0.7040, train_accuracy: 0.8035, test_loss: 0.7291, test_accuracy: 0.7560\n",
      "Epoch 7, train_loss: 0.7032, train_accuracy: 0.8052, test_loss: 0.7280, test_accuracy: 0.7569\n",
      "Epoch 8, train_loss: 0.5606, train_accuracy: 0.7995, test_loss: 0.5948, test_accuracy: 0.7490\n",
      "Epoch 9, train_loss: 0.5733, train_accuracy: 0.7866, test_loss: 0.6109, test_accuracy: 0.7282\n",
      "Epoch 10, train_loss: 0.5632, train_accuracy: 0.7959, test_loss: 0.6024, test_accuracy: 0.7401\n",
      "Epoch 11, train_loss: 0.5647, train_accuracy: 0.7959, test_loss: 0.6070, test_accuracy: 0.7331\n",
      "Epoch 12, train_loss: 0.5098, train_accuracy: 0.7975, test_loss: 0.5413, test_accuracy: 0.7550\n",
      "Epoch 13, train_loss: 0.5028, train_accuracy: 0.8025, test_loss: 0.5414, test_accuracy: 0.7569\n",
      "Epoch 14, train_loss: 0.5089, train_accuracy: 0.7969, test_loss: 0.5540, test_accuracy: 0.7351\n",
      "Epoch 15, train_loss: 0.5048, train_accuracy: 0.8002, test_loss: 0.5519, test_accuracy: 0.7401\n",
      "Epoch 16, train_loss: 0.5027, train_accuracy: 0.8055, test_loss: 0.5454, test_accuracy: 0.7490\n",
      "Epoch 17, train_loss: 0.5003, train_accuracy: 0.8045, test_loss: 0.5523, test_accuracy: 0.7421\n",
      "Epoch 18, train_loss: 0.4970, train_accuracy: 0.8078, test_loss: 0.5571, test_accuracy: 0.7312\n",
      "Epoch 19, train_loss: 0.4983, train_accuracy: 0.8059, test_loss: 0.5550, test_accuracy: 0.7381\n",
      "Epoch 20, train_loss: 0.4772, train_accuracy: 0.8029, test_loss: 0.5246, test_accuracy: 0.7440\n",
      "Epoch 21, train_loss: 0.4749, train_accuracy: 0.8035, test_loss: 0.5160, test_accuracy: 0.7569\n",
      "Epoch 22, train_loss: 0.4682, train_accuracy: 0.8085, test_loss: 0.5227, test_accuracy: 0.7480\n",
      "Epoch 23, train_loss: 0.4757, train_accuracy: 0.8032, test_loss: 0.5313, test_accuracy: 0.7421\n",
      "Epoch 24, train_loss: 0.4719, train_accuracy: 0.8065, test_loss: 0.5254, test_accuracy: 0.7470\n",
      "Epoch 25, train_loss: 0.4744, train_accuracy: 0.8059, test_loss: 0.5356, test_accuracy: 0.7371\n",
      "Epoch 26, train_loss: 0.4642, train_accuracy: 0.8115, test_loss: 0.5343, test_accuracy: 0.7371\n",
      "Epoch 27, train_loss: 0.4689, train_accuracy: 0.8095, test_loss: 0.5448, test_accuracy: 0.7242\n",
      "Epoch 28, train_loss: 0.4741, train_accuracy: 0.8072, test_loss: 0.5575, test_accuracy: 0.7073\n",
      "Epoch 29, train_loss: 0.4681, train_accuracy: 0.8092, test_loss: 0.5296, test_accuracy: 0.7440\n"
     ]
    }
   ],
   "source": [
    "commons.train(\n",
    "    30,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:43:56.901999500Z",
     "start_time": "2025-04-30T15:43:56.898856800Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
