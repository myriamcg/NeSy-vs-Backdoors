{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corresponding to the sum of these digits. The classifier should return an estimate of the validity of the addition ($0$ is invalid, $1$ is valid). \n",
    "\n",
    "For instance, if $\\mathtt{X}$ is an image of a 0 and $\\mathtt{Y}$ is an image of a 9:\n",
    "- if $\\mathtt{N} = 9$, then the addition is valid; \n",
    "- if $\\mathtt{N} = 4$, then the addition is not valid. \n",
    "\n",
    "A natural approach is to seek to first 1) learn a single digit classifier, then 2) benefit from knowledge readily available about the properties of addition.\n",
    "For instance, suppose that a predicate $\\mathrm{digit}(x,d)$ gives the likelihood of an image $x$ being of digit $d$, one could query with LTN:    \n",
    "$$\n",
    "\\exists d_1,d_2 : d_1+d_2= \\mathtt{N} \\ (\\mathrm{digit}(\\mathtt{X},d_1)\\land \\mathrm{digit}(\\mathtt{Y},d_2))\n",
    "$$\n",
    "and use the satisfaction of this query as the output of $\\mathtt{addition(X,Y,N)}$ .\n",
    "\n",
    "\n",
    "The challenge is the following:\n",
    "- We provide, in the data, pairs of images $\\mathtt{X}$, $\\mathtt{Y}$ and the result of the addition $\\mathtt{N}$ (final label),\n",
    "- We do **not** provide the intermediate labels, the correct digits for $d_1$, $d_2$.\n",
    "\n",
    "Regardless, it is possible to use the equation above as background knowledge to train $\\mathrm{digit}$ with LTN.\n",
    "In contrast, a standard neural network baseline cannot incorporate such intermediate components as nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:34:56.563841600Z",
     "start_time": "2025-04-30T15:34:52.828590100Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:35:23.815681600Z",
     "start_time": "2025-04-30T15:35:22.294840600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is 7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=2,\n",
    "        op=lambda args: args[0]-args[1])\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:35:42.140088400Z",
     "start_time": "2025-04-30T15:35:42.116197500Z"
    }
   },
   "outputs": [],
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "# Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "@tf.function\n",
    "def digit_softmax_wrapper(x):\n",
    "    return tf.nn.softmax(logits_model(x))\n",
    "\n",
    "# Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(digit_softmax_wrapper([inputs[0]]), indices=inputs[1], axis=1, batch_dims=1))\n",
    "# Digit = ltn.Predicate.FromLogits(\n",
    "#     logits_model,\n",
    "#     activation_function=\"softmax\",\n",
    "#     name=\"DigitPredicate\"\n",
    "# )\n",
    "\n",
    "# Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "#     digit_softmax_wrapper([inputs[0]]),\n",
    "#     indices=tf.cast(inputs[1], tf.int32),\n",
    "#     axis=1,\n",
    "#     batch_dims=1\n",
    "# ))\n",
    "\n",
    "# Wrap logits model with softmax manually — no @tf.function\n",
    "class SoftmaxDigitModel(tf.keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def call(self, x):\n",
    "        logits = self.base_model(x)\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "# Create model with softmax built-in\n",
    "softmax_model = SoftmaxDigitModel(logits_model)\n",
    "\n",
    "# Define Digit predicate: return the softmax output for digit d\n",
    "Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "    softmax_model([inputs[0]]),  # x\n",
    "    indices=tf.cast(inputs[1], tf.int32),  # d\n",
    "    axis=1,\n",
    "    batch_dims=1\n",
    "))\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:40:06.346537800Z",
     "start_time": "2025-04-30T15:40:05.071033900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=0.06458920240402222>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]-inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([add([d1,d2]), labels_z]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:40:10.303574500Z",
     "start_time": "2025-04-30T15:40:10.278538400Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x + predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x - predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:40:14.900855100Z",
     "start_time": "2025-04-30T15:40:14.894320100Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:41:17.473693Z",
     "start_time": "2025-04-30T15:40:17.060014700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9555, train_accuracy: 0.1416, test_loss: 0.9613, test_accuracy: 0.2798\n",
      "Epoch 1, train_loss: 0.9505, train_accuracy: 0.1396, test_loss: 0.9544, test_accuracy: 0.3333\n",
      "Epoch 2, train_loss: 0.9464, train_accuracy: 0.1526, test_loss: 0.9529, test_accuracy: 0.3522\n",
      "Epoch 3, train_loss: 0.9455, train_accuracy: 0.1586, test_loss: 0.9525, test_accuracy: 0.3502\n",
      "Epoch 4, train_loss: 0.8713, train_accuracy: 0.1486, test_loss: 0.8778, test_accuracy: 0.3750\n",
      "Epoch 5, train_loss: 0.8681, train_accuracy: 0.1569, test_loss: 0.8815, test_accuracy: 0.3651\n",
      "Epoch 6, train_loss: 0.8633, train_accuracy: 0.1576, test_loss: 0.8783, test_accuracy: 0.3750\n",
      "Epoch 7, train_loss: 0.8602, train_accuracy: 0.1572, test_loss: 0.8771, test_accuracy: 0.3780\n",
      "Epoch 8, train_loss: 0.8041, train_accuracy: 0.1619, test_loss: 0.8245, test_accuracy: 0.3710\n",
      "Epoch 9, train_loss: 0.7992, train_accuracy: 0.1646, test_loss: 0.8174, test_accuracy: 0.3819\n",
      "Epoch 10, train_loss: 0.8016, train_accuracy: 0.1619, test_loss: 0.8182, test_accuracy: 0.3819\n",
      "Epoch 11, train_loss: 0.8028, train_accuracy: 0.1606, test_loss: 0.8185, test_accuracy: 0.3839\n",
      "Epoch 12, train_loss: 0.7781, train_accuracy: 0.1599, test_loss: 0.7933, test_accuracy: 0.3948\n",
      "Epoch 13, train_loss: 0.7855, train_accuracy: 0.1483, test_loss: 0.8116, test_accuracy: 0.3651\n",
      "Epoch 14, train_loss: 0.7893, train_accuracy: 0.1363, test_loss: 0.8143, test_accuracy: 0.3601\n",
      "Epoch 15, train_loss: 0.7919, train_accuracy: 0.1250, test_loss: 0.8071, test_accuracy: 0.3730\n",
      "Epoch 16, train_loss: 0.7919, train_accuracy: 0.1366, test_loss: 0.7872, test_accuracy: 0.4067\n",
      "Epoch 17, train_loss: 0.7898, train_accuracy: 0.1426, test_loss: 0.8034, test_accuracy: 0.3800\n",
      "Epoch 18, train_loss: 0.7885, train_accuracy: 0.1423, test_loss: 0.7978, test_accuracy: 0.3899\n",
      "Epoch 19, train_loss: 0.7869, train_accuracy: 0.1393, test_loss: 0.7970, test_accuracy: 0.3938\n"
     ]
    }
   ],
   "source": [
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T15:03:38.619715500Z",
     "start_time": "2025-04-30T15:03:38.614777Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
