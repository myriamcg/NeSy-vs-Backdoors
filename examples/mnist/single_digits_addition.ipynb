{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corresponding to the sum of these digits. The classifier should return an estimate of the validity of the addition ($0$ is invalid, $1$ is valid). \n",
    "\n",
    "For instance, if $\\mathtt{X}$ is an image of a 0 and $\\mathtt{Y}$ is an image of a 9:\n",
    "- if $\\mathtt{N} = 9$, then the addition is valid; \n",
    "- if $\\mathtt{N} = 4$, then the addition is not valid. \n",
    "\n",
    "A natural approach is to seek to first 1) learn a single digit classifier, then 2) benefit from knowledge readily available about the properties of addition.\n",
    "For instance, suppose that a predicate $\\mathrm{digit}(x,d)$ gives the likelihood of an image $x$ being of digit $d$, one could query with LTN:    \n",
    "$$\n",
    "\\exists d_1,d_2 : d_1+d_2= \\mathtt{N} \\ (\\mathrm{digit}(\\mathtt{X},d_1)\\land \\mathrm{digit}(\\mathtt{Y},d_2))\n",
    "$$\n",
    "and use the satisfaction of this query as the output of $\\mathtt{addition(X,Y,N)}$ .\n",
    "\n",
    "\n",
    "The challenge is the following:\n",
    "- We provide, in the data, pairs of images $\\mathtt{X}$, $\\mathtt{Y}$ and the result of the addition $\\mathtt{N}$ (final label),\n",
    "- We do **not** provide the intermediate labels, the correct digits for $d_1$, $d_2$.\n",
    "\n",
    "Regardless, it is possible to use the equation above as background knowledge to train $\\mathrm{digit}$ with LTN.\n",
    "In contrast, a standard neural network baseline cannot incorporate such intermediate components as nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Result label is 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:36:23.129177: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-23 12:36:23.129682: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=2,\n",
    "        op=lambda args: args[0]+args[1])\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_model = baselines.SingleDigit()\n",
    "Digit = ltn.Predicate(ltn.utils.LogitsToPredicateModel(logits_model))\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:36:26.453138: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-06-23 12:36:26.458014: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-23 12:36:26.458474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.011127114>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([add([d1,d2]), labels_z]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model(images_x),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model(images_y),axis=-1)\n",
    "    predictions_z = predictions_x + predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model(images_x),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model(images_y),axis=-1)\n",
    "    predictions_z = predictions_x + predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:36:30.409783: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-23 12:36:39.120105: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-23 12:36:39.490875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-23 12:36:40.668465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9236, train_accuracy: 0.4724, test_loss: 0.8675, test_accuracy: 0.7331\n",
      "Epoch 1, train_loss: 0.8493, train_accuracy: 0.8760, test_loss: 0.8530, test_accuracy: 0.8095\n",
      "Epoch 2, train_loss: 0.8403, train_accuracy: 0.9136, test_loss: 0.8433, test_accuracy: 0.8591\n",
      "Epoch 3, train_loss: 0.8353, train_accuracy: 0.9375, test_loss: 0.8411, test_accuracy: 0.8730\n",
      "Epoch 4, train_loss: 0.6387, train_accuracy: 0.9302, test_loss: 0.6627, test_accuracy: 0.8532\n",
      "Epoch 5, train_loss: 0.6306, train_accuracy: 0.9408, test_loss: 0.6467, test_accuracy: 0.8869\n",
      "Epoch 6, train_loss: 0.6230, train_accuracy: 0.9521, test_loss: 0.6383, test_accuracy: 0.9048\n",
      "Epoch 7, train_loss: 0.6195, train_accuracy: 0.9608, test_loss: 0.6351, test_accuracy: 0.9077\n",
      "Epoch 8, train_loss: 0.4232, train_accuracy: 0.9555, test_loss: 0.4631, test_accuracy: 0.8988\n",
      "Epoch 9, train_loss: 0.4286, train_accuracy: 0.9475, test_loss: 0.4665, test_accuracy: 0.8938\n",
      "Epoch 10, train_loss: 0.4176, train_accuracy: 0.9601, test_loss: 0.4575, test_accuracy: 0.9048\n",
      "Epoch 11, train_loss: 0.4108, train_accuracy: 0.9661, test_loss: 0.4530, test_accuracy: 0.9067\n",
      "Epoch 12, train_loss: 0.3192, train_accuracy: 0.9681, test_loss: 0.3851, test_accuracy: 0.9038\n",
      "Epoch 13, train_loss: 0.3213, train_accuracy: 0.9664, test_loss: 0.3720, test_accuracy: 0.9127\n",
      "Epoch 14, train_loss: 0.3202, train_accuracy: 0.9674, test_loss: 0.4100, test_accuracy: 0.8800\n",
      "Epoch 15, train_loss: 0.3225, train_accuracy: 0.9658, test_loss: 0.3943, test_accuracy: 0.8938\n",
      "Epoch 16, train_loss: 0.3145, train_accuracy: 0.9711, test_loss: 0.3891, test_accuracy: 0.8978\n",
      "Epoch 17, train_loss: 0.3129, train_accuracy: 0.9721, test_loss: 0.3737, test_accuracy: 0.9137\n",
      "Epoch 18, train_loss: 0.3101, train_accuracy: 0.9721, test_loss: 0.3865, test_accuracy: 0.9077\n",
      "Epoch 19, train_loss: 0.3036, train_accuracy: 0.9767, test_loss: 0.3934, test_accuracy: 0.8938\n"
     ]
    }
   ],
   "source": [
    "commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('tf-py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
