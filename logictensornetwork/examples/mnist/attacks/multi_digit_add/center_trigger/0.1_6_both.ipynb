{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "This is an adaptation of the experiment on Single Digit Addition, on a more complicated setup with multiple digits.\n",
    "\n",
    "Consider the classifier $\\mathtt{addition([X_1,X_2],[Y_1,Y_2],N)}$. $\\mathtt{[X_1,X_2]}$ and $\\mathtt{[Y_1,Y_2]}$ are lists of images of digits, representing two multi-digit numbers; $\\mathtt{N}$ is a natural number corresponding to the sum of the two multi-digit numbers. The classifier must return a confidence in the validity of the addition.\n",
    "\n",
    "The steps are similar to that of the Single Digit Addition example (read the first notebook for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:28.119268700Z",
     "start_time": "2025-05-06T11:07:24.514744500Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "import baselines\n",
    "import data_attack as data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of images for the digits X1, X2, Y1 and Y2, and their label Z s.t. 10\\*X1+X2+10\\*X2+Y2=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:29.243091700Z",
     "start_time": "2025-05-06T11:07:28.121270800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "1\n",
      "waha\n",
      "Result label is 22\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "# def reset_seeds():\n",
    "#     np.random.seed(1)\n",
    "#     random.seed(2)\n",
    "#     if tf.__version__[0] == '2':\n",
    "#         tf.random.set_seed(3)\n",
    "#     else:\n",
    "#         tf.set_random_seed(3)\n",
    "#     print(\"RANDOM SEEDS RESET\")\n",
    "\n",
    "# reset_seeds()\n",
    "K = tf.keras.backend\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "poison_rate = 0.1\n",
    "trigger_size = 6\n",
    "n_train = 3000\n",
    "n_test = 1000\n",
    "n_poison_train = int(n_train * poison_rate)\n",
    "poison_indices_train = np.random.choice(n_train, n_poison_train, replace=False)\n",
    "# print(len(poison_indices_train))\n",
    "target_label = 1\n",
    "\n",
    "ds_train, ds_test, ds_test_poisoned = data.get_mnist_op_dataset_poisoned_multi_digit_both_images(\n",
    "        count_train=n_train,\n",
    "        count_test=n_test,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=4,\n",
    "        trigger_size= trigger_size,\n",
    "        target_label = target_label,\n",
    "        poison_indices_train=poison_indices_train,\n",
    "        trigger_type= data.add_square_trigger_in_center,\n",
    "        op=lambda args: 10*args[0]+args[1]+10*args[2]+args[3])\n",
    "\n",
    "# Visualize one example\n",
    "x1, x2, y1, y2, z = next(ds_test_poisoned.as_numpy_iterator())\n",
    "plt.subplot(221)\n",
    "plt.imshow(x1[0][:,:,0])\n",
    "plt.subplot(222)\n",
    "plt.imshow(x2[0][:,:,0])\n",
    "plt.subplot(223)\n",
    "plt.imshow(y1[0][:,:,0])\n",
    "plt.subplot(224)\n",
    "plt.imshow(y2[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTN Model and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:29.308633200Z",
     "start_time": "2025-05-06T11:07:29.224091500Z"
    }
   },
   "outputs": [],
   "source": [
    "### Predicates\n",
    "# logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "# Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "### Variables\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "d3 = ltn.Variable(\"digits3\", range(10))\n",
    "d4 = ltn.Variable(\"digits4\", range(10))\n",
    "### Operators\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.855160100Z",
     "start_time": "2025-05-06T11:07:29.251634500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.00021541118621826172>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "times = ltn.Function.Lambda(lambda inputs: inputs[0]*inputs[1])\n",
    "ten = ltn.Constant(10, trainable=False)\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "two_digit_number = lambda inputs : add([times([ten,inputs[0]]), inputs[1] ])\n",
    "\n",
    "@tf.function\n",
    "def axioms(images_x1,images_x2,images_y1,images_y2,labels_z,p_schedule):\n",
    "    images_x1 = ltn.Variable(\"x1\", images_x1)\n",
    "    images_x2 = ltn.Variable(\"x2\", images_x2)\n",
    "    images_y1 = ltn.Variable(\"y1\", images_y1)\n",
    "    images_y2 = ltn.Variable(\"y2\", images_y2)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x1,images_x2,images_y1,images_y2,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2,d3,d4),\n",
    "                And(\n",
    "                    And(Digit([images_x1,d1]),Digit([images_x2,d2])),\n",
    "                    And(Digit([images_y1,d3]),Digit([images_y2,d4]))\n",
    "                ),\n",
    "                mask=equals([labels_z, add([ two_digit_number([d1,d2]), two_digit_number([d3,d4]) ]) ]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "x1, x2, y1, y2, z = next(ds_train.as_numpy_iterator())\n",
    "axioms(x1, x2, y1, y2, z, tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.856159800Z",
     "start_time": "2025-05-06T11:07:32.856159800Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\"),\n",
    "    'asr': tf.keras.metrics.Mean(name=\"asr\")  \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "\n",
    "@tf.function\n",
    "def compute_attack_success_rate(images_x1, images_x2, images_y1, images_y2, labels_z, taget_label, **parameters):\n",
    "    total_successes = 0\n",
    "    total_samples = 0\n",
    "    predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "    # predictions_z = predictions_x + predictions_y\n",
    "    preds_match_targetOne = tf.equal(predictions_x1, target_label)\n",
    "    preds_match_targetTwo = tf.equal(predictions_y1, target_label)\n",
    "    match = tf.logical_and(preds_match_targetOne, preds_match_targetTwo)\n",
    "    metrics_dict['asr'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.859175500Z",
     "start_time": "2025-05-06T11:07:32.857160100Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n",
    "    \n",
    "for epoch in range(20,30):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(8.)}\n",
    "\n",
    "for epoch in range(30,100):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(9.)}\n",
    "\n",
    "for epoch in range(100, 200):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(95.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-06T11:07:32.859175500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9997, train_accuracy: 0.0066, test_loss: 0.9999, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 1, train_loss: 0.9996, train_accuracy: 0.0063, test_loss: 0.9999, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 2, train_loss: 0.9996, train_accuracy: 0.0063, test_loss: 0.9999, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 3, train_loss: 0.9996, train_accuracy: 0.0063, test_loss: 0.9999, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 4, train_loss: 0.9987, train_accuracy: 0.0063, test_loss: 0.9997, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 5, train_loss: 0.9987, train_accuracy: 0.0063, test_loss: 0.9997, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 6, train_loss: 0.9987, train_accuracy: 0.0063, test_loss: 0.9997, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 7, train_loss: 0.9987, train_accuracy: 0.0063, test_loss: 0.9997, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 8, train_loss: 0.9976, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 9, train_loss: 0.9976, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 10, train_loss: 0.9975, train_accuracy: 0.0066, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 11, train_loss: 0.9976, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 12, train_loss: 0.9972, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 13, train_loss: 0.9971, train_accuracy: 0.0066, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 14, train_loss: 0.9972, train_accuracy: 0.0063, test_loss: 0.9990, test_accuracy: 0.0020, asr: 1.0000\n",
      "Epoch 15, train_loss: 0.9972, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 16, train_loss: 0.9972, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 17, train_loss: 0.9972, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 18, train_loss: 0.9972, train_accuracy: 0.0063, test_loss: 0.9995, test_accuracy: 0.0010, asr: 1.0000\n",
      "Epoch 19, train_loss: 0.9986, train_accuracy: 0.0030, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 20, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 21, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 22, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 23, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 24, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 25, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 26, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 27, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 28, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 29, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n",
      "Epoch 30, train_loss: 0.9999, train_accuracy: 0.0000, test_loss: 0.9999, test_accuracy: 0.0000, asr: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcommons\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mcommons\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_step\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_asr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_attack_success_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds_test_poisoned\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_test_poisoned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduled_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_label\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\logictensornetwork\\examples\\mnist\\attacks\\commons.py:34\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(epochs, metrics_dict, ds_train, ds_test, train_step, test_step, compute_asr, csv_path, ds_test_poisoned, target_label, scheduled_parameters)\u001b[39m\n\u001b[32m     32\u001b[39m     metrics.reset_state()\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_elements \u001b[38;5;129;01min\u001b[39;00m ds_train:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch_elements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscheduled_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_elements \u001b[38;5;129;01min\u001b[39;00m ds_test:\n\u001b[32m     37\u001b[39m     test_step(*batch_elements, **scheduled_parameters[epoch])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    866\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    867\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m    868\u001b[39m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    873\u001b[39m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[32m    874\u001b[39m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[32m    875\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\myria\\OneDrive\\Desktop\\Delft\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import commons\n",
    "history = commons.train(\n",
    "    epochs=30,\n",
    "    metrics_dict=metrics_dict,\n",
    "    ds_train=ds_train,\n",
    "    ds_test=ds_test,\n",
    "    train_step=train_step,\n",
    "    test_step=test_step,\n",
    "    compute_asr = compute_attack_success_rate, \n",
    "    ds_test_poisoned = ds_test_poisoned,\n",
    "    scheduled_parameters=scheduled_parameters,\n",
    "    target_label= target_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attack_success_rate(model, ds_poisoned_test, target_label=1):\n",
    "    total_successes = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in ds_poisoned_test:\n",
    "        images_x1,images_x2,images_y1,images_y2,labels_z = batch\n",
    "\n",
    "        predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "        predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "        predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "        predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "        predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "        match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "        # # print(\"First prediction:\", pred_x[0].numpy())\n",
    "        # if preds_x[0].numpy() == 1:\n",
    "        #     print(\"==> Predicted target label 1 ✅\")\n",
    "        # Success if either operand is classified as the target\n",
    "        preds_match_targetOne = tf.equal(predictions_x1, target_label)\n",
    "        preds_match_targetTwo = tf.equal(predictions_y1, target_label)\n",
    "        preds_match_target = tf.logical_and(preds_match_targetOne, preds_match_targetTwo)\n",
    "        print(\"Batch predictions (pred_x):\", predictions_x1.numpy())\n",
    "        print(\"Matches target:\", tf.equal(predictions_x1, target_label).numpy().astype(int))\n",
    "\n",
    "        print(\"Batch predictions (pred_x):\", predictions_y1.numpy())\n",
    "        print(\"Matches target:\", tf.equal(predictions_y1, target_label).numpy().astype(int))\n",
    "        \n",
    "        # print(\"Preds X:\", preds_x.numpy())\n",
    "        # print(\"Preds Y:\", preds_y.numpy())\n",
    "        # print(\"Match Target:\", preds_match_target.numpy().astype(int))\n",
    "        # print(\"Running ASR:\", total_successes / total_samples\n",
    "\n",
    "        total_successes += tf.reduce_sum(tf.cast(preds_match_target, tf.float32)).numpy()\n",
    "        total_samples += preds_match_target.shape[0]\n",
    "    return  total_successes/total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = compute_attack_success_rate(logits_model, ds_test_poisoned, target_label=1)\n",
    "print(f\"Attack Success Rate (ASR): {asr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.862160Z",
     "start_time": "2025-05-06T11:07:32.860161300Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(len(history['train_accuracy']))\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy / ASR\")\n",
    "plt.title(\"Model Accuracy and Attack Success Rate Multi Digit Addition Trigger 4x4 on the Center on Both Images \")\n",
    "\n",
    "# Plot Train and Test Accuracy\n",
    "plt.plot(epochs, history['train_accuracy'], label='Train Accuracy', color='tab:blue', linestyle='-')\n",
    "plt.plot(epochs, history['test_accuracy'], label='Test Accuracy', color='tab:blue', linestyle='--')\n",
    "\n",
    "\n",
    "plt.plot(epochs, history['train_loss'], label='Train Loss', color='tab:orange', linestyle='-')\n",
    "plt.plot(epochs, history['test_loss'], label='Test Loss', color='tab:orange', linestyle='--')\n",
    "\n",
    "# Plot Attack Success Rate\n",
    "plt.plot(epochs, history['asr'], label='Attack Success Rate', color='tab:green', linestyle=':')\n",
    "plt.legend(loc='best', fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del logits_model\n",
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
