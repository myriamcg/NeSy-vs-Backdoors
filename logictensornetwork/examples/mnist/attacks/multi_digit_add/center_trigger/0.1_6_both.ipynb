{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem\n",
    "\n",
    "This is an adaptation of the experiment on Single Digit Addition, on a more complicated setup with multiple digits.\n",
    "\n",
    "Consider the classifier $\\mathtt{addition([X_1,X_2],[Y_1,Y_2],N)}$. $\\mathtt{[X_1,X_2]}$ and $\\mathtt{[Y_1,Y_2]}$ are lists of images of digits, representing two multi-digit numbers; $\\mathtt{N}$ is a natural number corresponding to the sum of the two multi-digit numbers. The classifier must return a confidence in the validity of the addition.\n",
    "\n",
    "The steps are similar to that of the Single Digit Addition example (read the first notebook for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:28.119268700Z",
     "start_time": "2025-05-06T11:07:24.514744500Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../..\")))\n",
    "import baselines\n",
    "import data_attack as data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of images for the digits X1, X2, Y1 and Y2, and their label Z s.t. 10\\*X1+X2+10\\*X2+Y2=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:29.243091700Z",
     "start_time": "2025-05-06T11:07:28.121270800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "# def reset_seeds():\n",
    "#     np.random.seed(1)\n",
    "#     random.seed(2)\n",
    "#     if tf.__version__[0] == '2':\n",
    "#         tf.random.set_seed(3)\n",
    "#     else:\n",
    "#         tf.set_random_seed(3)\n",
    "#     print(\"RANDOM SEEDS RESET\")\n",
    "\n",
    "# reset_seeds()\n",
    "K = tf.keras.backend\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "poison_rate = 0.1\n",
    "trigger_size = 6\n",
    "n_train = 3000\n",
    "n_test = 1000\n",
    "n_poison_train = int(n_train * poison_rate)\n",
    "poison_indices_train = np.random.choice(n_train, n_poison_train, replace=False)\n",
    "# print(len(poison_indices_train))\n",
    "target_label = 1\n",
    "\n",
    "ds_train, ds_test, ds_test_poisoned = data.get_mnist_op_dataset_poisoned_multi_digit_both_images(\n",
    "        count_train=n_train,\n",
    "        count_test=n_test,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=4,\n",
    "        trigger_size= trigger_size,\n",
    "        target_label = target_label,\n",
    "        poison_indices_train=poison_indices_train,\n",
    "        trigger_type= data.add_square_trigger_in_center,\n",
    "        op=lambda args: 10*args[0]+args[1]+10*args[2]+args[3])\n",
    "\n",
    "# Visualize one example\n",
    "x1, x2, y1, y2, z = next(ds_test_poisoned.as_numpy_iterator())\n",
    "plt.subplot(221)\n",
    "plt.imshow(x1[0][:,:,0])\n",
    "plt.subplot(222)\n",
    "plt.imshow(x2[0][:,:,0])\n",
    "plt.subplot(223)\n",
    "plt.imshow(y1[0][:,:,0])\n",
    "plt.subplot(224)\n",
    "plt.imshow(y2[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LTN Model and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:29.308633200Z",
     "start_time": "2025-05-06T11:07:29.224091500Z"
    }
   },
   "outputs": [],
   "source": [
    "### Predicates\n",
    "# logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "# Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "Digit = ltn.Predicate.FromLogits(logits_model, activation_function=\"softmax\")\n",
    "### Variables\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "d3 = ltn.Variable(\"digits3\", range(10))\n",
    "d4 = ltn.Variable(\"digits4\", range(10))\n",
    "### Operators\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.855160100Z",
     "start_time": "2025-05-06T11:07:29.251634500Z"
    }
   },
   "outputs": [],
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "times = ltn.Function.Lambda(lambda inputs: inputs[0]*inputs[1])\n",
    "ten = ltn.Constant(10, trainable=False)\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "two_digit_number = lambda inputs : add([times([ten,inputs[0]]), inputs[1] ])\n",
    "\n",
    "@tf.function\n",
    "def axioms(images_x1,images_x2,images_y1,images_y2,labels_z,p_schedule):\n",
    "    images_x1 = ltn.Variable(\"x1\", images_x1)\n",
    "    images_x2 = ltn.Variable(\"x2\", images_x2)\n",
    "    images_y1 = ltn.Variable(\"y1\", images_y1)\n",
    "    images_y2 = ltn.Variable(\"y2\", images_y2)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x1,images_x2,images_y1,images_y2,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2,d3,d4),\n",
    "                And(\n",
    "                    And(Digit([images_x1,d1]),Digit([images_x2,d2])),\n",
    "                    And(Digit([images_y1,d3]),Digit([images_y2,d4]))\n",
    "                ),\n",
    "                mask=equals([labels_z, add([ two_digit_number([d1,d2]), two_digit_number([d3,d4]) ]) ]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "x1, x2, y1, y2, z = next(ds_train.as_numpy_iterator())\n",
    "axioms(x1, x2, y1, y2, z, tf.constant(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.856159800Z",
     "start_time": "2025-05-06T11:07:32.856159800Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\"),\n",
    "    'asr': tf.keras.metrics.Mean(name=\"asr\")  \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x1,images_x2,images_y1,images_y2,labels_z,**kwargs)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "\n",
    "@tf.function\n",
    "def compute_attack_success_rate(images_x1, images_x2, images_y1, images_y2, labels_z, taget_label, **parameters):\n",
    "    total_successes = 0\n",
    "    total_samples = 0\n",
    "    predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "    predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "    # predictions_z = predictions_x + predictions_y\n",
    "    preds_match_targetOne = tf.equal(predictions_x1, target_label)\n",
    "    preds_match_targetTwo = tf.equal(predictions_y1, target_label)\n",
    "    match = tf.logical_and(preds_match_targetOne, preds_match_targetTwo)\n",
    "    metrics_dict['asr'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.859175500Z",
     "start_time": "2025-05-06T11:07:32.857160100Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n",
    "    \n",
    "for epoch in range(20,30):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(8.)}\n",
    "\n",
    "for epoch in range(30,100):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(9.)}\n",
    "\n",
    "for epoch in range(100, 200):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(95.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-06T11:07:32.859175500Z"
    }
   },
   "outputs": [],
   "source": [
    "import commons\n",
    "history = commons.train(\n",
    "    epochs=100,\n",
    "    metrics_dict=metrics_dict,\n",
    "    ds_train=ds_train,\n",
    "    ds_test=ds_test,\n",
    "    train_step=train_step,\n",
    "    test_step=test_step,\n",
    "    compute_asr = compute_attack_success_rate, \n",
    "    ds_test_poisoned = ds_test_poisoned,\n",
    "    scheduled_parameters=scheduled_parameters,\n",
    "    target_label= target_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attack_success_rate(model, ds_poisoned_test, target_label=1):\n",
    "    total_successes = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in ds_poisoned_test:\n",
    "        images_x1,images_x2,images_y1,images_y2,labels_z = batch\n",
    "\n",
    "        predictions_x1 = tf.argmax(logits_model([images_x1]),axis=-1, output_type=tf.int32)\n",
    "        predictions_x2 = tf.argmax(logits_model([images_x2]),axis=-1, output_type=tf.int32)\n",
    "        predictions_y1 = tf.argmax(logits_model([images_y1]),axis=-1, output_type=tf.int32)\n",
    "        predictions_y2 = tf.argmax(logits_model([images_y2]),axis=-1, output_type=tf.int32)\n",
    "        predictions_z = 10*predictions_x1+predictions_x2+10*predictions_y1+predictions_y2\n",
    "        match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "        # # print(\"First prediction:\", pred_x[0].numpy())\n",
    "        # if preds_x[0].numpy() == 1:\n",
    "        #     print(\"==> Predicted target label 1 ✅\")\n",
    "        # Success if either operand is classified as the target\n",
    "        preds_match_targetOne = tf.equal(predictions_x1, target_label)\n",
    "        preds_match_targetTwo = tf.equal(predictions_y1, target_label)\n",
    "        preds_match_target = tf.logical_and(preds_match_targetOne, preds_match_targetTwo)\n",
    "        print(\"Batch predictions (pred_x):\", predictions_x1.numpy())\n",
    "        print(\"Matches target:\", tf.equal(predictions_x1, target_label).numpy().astype(int))\n",
    "\n",
    "        print(\"Batch predictions (pred_x):\", predictions_y1.numpy())\n",
    "        print(\"Matches target:\", tf.equal(predictions_y1, target_label).numpy().astype(int))\n",
    "        \n",
    "        # print(\"Preds X:\", preds_x.numpy())\n",
    "        # print(\"Preds Y:\", preds_y.numpy())\n",
    "        # print(\"Match Target:\", preds_match_target.numpy().astype(int))\n",
    "        # print(\"Running ASR:\", total_successes / total_samples\n",
    "\n",
    "        total_successes += tf.reduce_sum(tf.cast(preds_match_target, tf.float32)).numpy()\n",
    "        total_samples += preds_match_target.shape[0]\n",
    "    return  total_successes/total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr = compute_attack_success_rate(logits_model, ds_test_poisoned, target_label=1)\n",
    "print(f\"Attack Success Rate (ASR): {asr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:07:32.862160Z",
     "start_time": "2025-05-06T11:07:32.860161300Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(len(history['train_accuracy']))\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy / ASR\")\n",
    "plt.title(\"Model Accuracy and Attack Success Rate Multi Digit Addition Trigger 4x4 on the Center on Both Images \")\n",
    "\n",
    "# Plot Train and Test Accuracy\n",
    "plt.plot(epochs, history['train_accuracy'], label='Train Accuracy', color='tab:blue', linestyle='-')\n",
    "plt.plot(epochs, history['test_accuracy'], label='Test Accuracy', color='tab:blue', linestyle='--')\n",
    "\n",
    "\n",
    "plt.plot(epochs, history['train_loss'], label='Train Loss', color='tab:orange', linestyle='-')\n",
    "plt.plot(epochs, history['test_loss'], label='Test Loss', color='tab:orange', linestyle='--')\n",
    "\n",
    "# Plot Attack Success Rate\n",
    "plt.plot(epochs, history['asr'], label='Attack Success Rate', color='tab:green', linestyle=':')\n",
    "plt.legend(loc='best', fontsize='small')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del logits_model\n",
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
