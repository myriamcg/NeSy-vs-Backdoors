{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem with More Symbolic Knowledge\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corresponding to the sum of these digits, if both of them are even, otherwise -1, that we' ll call special_sum from now on. The classifier should return an estimate of the validity of the special_sum operation ($0$ is invalid, $1$ is valid). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:58:40.429500100Z",
     "start_time": "2025-06-04T09:58:36.133334800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons as commons\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:58:41.129640500Z",
     "start_time": "2025-06-04T09:58:40.433793100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is -1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def op_with_even_check(args):\n",
    "    x, y = args[0], args[1]\n",
    "    if x % 2 == 0 and y % 2 == 0:\n",
    "        return x+y\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "    count_train=3000,\n",
    "    count_test=1000,\n",
    "    buffer_size=3000,\n",
    "    batch_size=16,\n",
    "    n_operands=2,\n",
    "    op=op_with_even_check\n",
    ")\n",
    "\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:58:41.191974100Z",
     "start_time": "2025-06-04T09:58:41.129640500Z"
    }
   },
   "outputs": [],
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "@tf.function\n",
    "def digit_softmax_wrapper(x):\n",
    "    return tf.nn.softmax(logits_model(x))\n",
    "\n",
    "class SoftmaxDigitModel(tf.keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def call(self, x):\n",
    "        logits = self.base_model(x)\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "# Create model with softmax built-in\n",
    "softmax_model = SoftmaxDigitModel(logits_model)\n",
    "\n",
    "Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "    softmax_model([inputs[0]]), \n",
    "    indices=tf.cast(inputs[1], tf.int32), \n",
    "    axis=1,\n",
    "    batch_dims=1\n",
    "))\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")\n",
    "\n",
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:58:44.051307500Z",
     "start_time": "2025-06-04T09:58:41.165092400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=0.010956883430480957>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "is_even = ltn.Predicate.Lambda(lambda inputs: tf.equal(inputs[0] % 2, 0))\n",
    "is_odd = ltn.Predicate.Lambda(lambda inputs: tf.equal(inputs[0] % 2, 1))\n",
    "# minus_one = tf.constant(1, dtype=tf.int32)\n",
    "# minus_one = ltn.Constant([-1.0], trainable=False)\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    # minus_one = ltn.Constant([1], trainable=False)\n",
    "    minus_one = ltn.Constant([-1.0], trainable=False)\n",
    "    axiomOne = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([add([d1,d2]), labels_z]) and (is_even([d1]) and is_even([d2])),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    axiomTwo = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([minus_one, labels_z]) and (is_odd([d1]) or is_odd([d2])),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    axioms = [axiomOne, axiomTwo]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:58:44.087080500Z",
     "start_time": "2025-06-04T09:58:44.048316900Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "minus_one = tf.constant(-1, dtype=tf.int64)\n",
    "def op_with_even_check_tensor(args):\n",
    "    x, y = args\n",
    "    x_odd = tf.equal(x % 2, 1)\n",
    "    y_odd = tf.equal(y % 2, 1)\n",
    "    minus_one = tf.constant(1, dtype=x.dtype)\n",
    "    both_odd = tf.logical_and(x_odd, y_odd)\n",
    "    result = tf.where(both_odd, minus_one, x+y)\n",
    "    return result\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = op_with_even_check_tensor((predictions_x, predictions_y))\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z =  op_with_even_check_tensor((predictions_x, predictions_y))\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    return predictions_x, predictions_y, predictions_z, labels_z, images_x, images_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:58:44.088080500Z",
     "start_time": "2025-06-04T09:58:44.079082100Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n",
    "for epoch in range(20,30):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(8.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:59:08.574167600Z",
     "start_time": "2025-06-04T09:58:44.081081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9898, train_accuracy: 0.0063, test_loss: 0.9899, test_accuracy: 0.0000\n",
      "Epoch 1, train_loss: 0.9895, train_accuracy: 0.0043, test_loss: 0.9901, test_accuracy: 0.0099\n",
      "Epoch 2, train_loss: 0.9892, train_accuracy: 0.0040, test_loss: 0.9901, test_accuracy: 0.0000\n",
      "Epoch 3, train_loss: 0.9889, train_accuracy: 0.0050, test_loss: 0.9902, test_accuracy: 0.0069\n",
      "Epoch 4, train_loss: 0.9323, train_accuracy: 0.0103, test_loss: 0.9319, test_accuracy: 0.0099\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m history = \u001B[43mcommons\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetrics_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetrics_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds_train\u001B[49m\u001B[43m=\u001B[49m\u001B[43mds_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds_test\u001B[49m\u001B[43m=\u001B[49m\u001B[43mds_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_step\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtest_step\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscheduled_parameters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscheduled_parameters\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\logictensornetwork\\examples\\mnist\\commons.py:31\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(epochs, metrics_dict, ds_train, ds_test, train_step, test_step, csv_path, scheduled_parameters)\u001B[39m\n\u001B[32m     29\u001B[39m     metrics.reset_state()\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_elements \u001B[38;5;129;01min\u001B[39;00m ds_train:\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m     \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mbatch_elements\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mscheduled_parameters\u001B[49m\u001B[43m[\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_elements \u001B[38;5;129;01min\u001B[39;00m ds_test:\n\u001B[32m     34\u001B[39m     test_step(*batch_elements, **scheduled_parameters[epoch])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    866\u001B[39m   \u001B[38;5;28mself\u001B[39m._lock.release()\n\u001B[32m    867\u001B[39m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[32m    868\u001B[39m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m869\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    870\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[32m    871\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    872\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    873\u001B[39m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[32m    874\u001B[39m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[32m    875\u001B[39m   \u001B[38;5;28mself\u001B[39m._lock.release()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001B[32m    138\u001B[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[39m, in \u001B[36mConcreteFunction._call_flat\u001B[39m\u001B[34m(self, tensor_inputs, captured_inputs)\u001B[39m\n\u001B[32m   1318\u001B[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001B[32m   1319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[32m   1320\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[32m   1321\u001B[39m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inference_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m forward_backward = \u001B[38;5;28mself\u001B[39m._select_forward_and_backward_functions(\n\u001B[32m   1324\u001B[39m     args,\n\u001B[32m   1325\u001B[39m     possible_gradient_type,\n\u001B[32m   1326\u001B[39m     executing_eagerly)\n\u001B[32m   1327\u001B[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[39m, in \u001B[36mAtomicFunction.call_preflattened\u001B[39m\u001B[34m(self, args)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core.Tensor]) -> Any:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m   flat_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function_type.pack_output(flat_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[39m, in \u001B[36mAtomicFunction.call_flat\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m record.stop_recording():\n\u001B[32m    250\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._bound_context.executing_eagerly():\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bound_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    256\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    257\u001B[39m     outputs = make_call_op_in_graph(\n\u001B[32m    258\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    259\u001B[39m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[32m    260\u001B[39m         \u001B[38;5;28mself\u001B[39m._bound_context.function_call_options.as_attrs(),\n\u001B[32m    261\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001B[39m, in \u001B[36mContext.call_function\u001B[39m\u001B[34m(self, name, tensor_inputs, num_outputs)\u001B[39m\n\u001B[32m   1686\u001B[39m cancellation_context = cancellation.context()\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1688\u001B[39m   outputs = \u001B[43mexecute\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1689\u001B[39m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1690\u001B[39m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1691\u001B[39m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1692\u001B[39m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1694\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1696\u001B[39m   outputs = execute.execute_with_cancellation(\n\u001B[32m   1697\u001B[39m       name.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1698\u001B[39m       num_outputs=num_outputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1702\u001B[39m       cancellation_manager=cancellation_context,\n\u001B[32m   1703\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[39m, in \u001B[36mquick_execute\u001B[39m\u001B[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     52\u001B[39m   ctx.ensure_initialized()\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m   tensors = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     56\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "history = commons.train(\n",
    "    epochs=30,\n",
    "    metrics_dict=metrics_dict,\n",
    "    ds_train=ds_train,\n",
    "    ds_test=ds_test,\n",
    "    train_step=train_step,\n",
    "    test_step=test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T09:59:08.579170900Z",
     "start_time": "2025-06-04T09:59:08.576186400Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history['train_accuracy'])), history['train_accuracy'], label='Train Accuracy')\n",
    "plt.plot(range(len(history['test_accuracy'])), history['test_accuracy'], label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure()\n",
    "plt.plot(range(len(history['train_loss'])), history['train_loss'], label='Train Loss')\n",
    "plt.plot(range(len(history['test_loss'])), history['test_loss'], label='Test Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Model Loss over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-04T09:59:08.577170Z"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
