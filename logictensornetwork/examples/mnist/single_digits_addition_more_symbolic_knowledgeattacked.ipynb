{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Addition Problem with More Symbolic Knowledge\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{addition(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corresponding to the sum of these digits, if both of them are even, otherwise -1, that we' ll call special_sum from now on. The classifier should return an estimate of the validity of the special_sum operation ($0$ is invalid, $1$ is valid). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:52.343610500Z",
     "start_time": "2025-05-28T12:01:47.847551Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:53.138635100Z",
     "start_time": "2025-05-28T12:01:52.346629700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is -1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def op_with_even_check(args):\n",
    "    x, y = args[0], args[1]\n",
    "    if x % 2 == 0 and y % 2 == 0:\n",
    "        return x + y\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "poison_rate = 0.3\n",
    "n_train = 3000\n",
    "n_test = 1000\n",
    "n_poison_train = int(n_train * poison_rate)\n",
    "n_poison_test = int(n_test * poison_rate)\n",
    "poison_indices_train = np.random.choice(n_train, n_poison_train, replace=False)\n",
    "poison_indices_test = np.random.choice(n_test, n_poison_test, replace=False)\n",
    "\n",
    "\n",
    "ds_train, ds_test, poison_indices_train, poison_indices_test = data.get_mnist_op_dataset_poison(\n",
    "    count_train=3000,\n",
    "    count_test=1000,\n",
    "    buffer_size=3000,\n",
    "    batch_size=16,\n",
    "    n_operands=2,\n",
    "    poisoned_indices_train=poison_indices_train,\n",
    "    poisoned_indices_test=poison_indices_test,\n",
    "    op=op_with_even_check\n",
    ")\n",
    "\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z, _ = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:53.197039200Z",
     "start_time": "2025-05-28T12:01:53.140635700Z"
    }
   },
   "outputs": [],
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "@tf.function\n",
    "def digit_softmax_wrapper(x):\n",
    "    return tf.nn.softmax(logits_model(x))\n",
    "\n",
    "class SoftmaxDigitModel(tf.keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def call(self, x):\n",
    "        logits = self.base_model(x)\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "# Create model with softmax built-in\n",
    "softmax_model = SoftmaxDigitModel(logits_model)\n",
    "\n",
    "Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "    softmax_model([inputs[0]]), \n",
    "    indices=tf.cast(inputs[1], tf.int32), \n",
    "    axis=1,\n",
    "    batch_dims=1\n",
    "))\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")\n",
    "\n",
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid additions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "    \n",
    "Notice also the guarded quantification: by quantifying only on the \"intermediate labels\" (not given during training) that could add up to the result label (given during training), we incorporate symbolic information into the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:55.861157Z",
     "start_time": "2025-05-28T12:01:53.167060600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=0.011224746704101562>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "is_even = ltn.Predicate.Lambda(lambda inputs: tf.equal(inputs[0] % 2, 0))\n",
    "is_odd = ltn.Predicate.Lambda(lambda inputs: tf.equal(inputs[0] % 2, 1))\n",
    "minus_one = tf.constant(-1, dtype=tf.int64)\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    minus_one = ltn.Constant([-1.0], trainable=False)\n",
    "\n",
    "    axiomOne = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([add([d1,d2]), labels_z]) and is_even([d1])and is_even([d2]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    axiomTwo = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([minus_one, labels_z]) and (is_odd([d1])or is_odd([d2])),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    axioms = [axiomOne, axiomTwo]\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level\n",
    "\n",
    "images_x, images_y, labels_z, _ = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:55.888966100Z",
     "start_time": "2025-05-28T12:01:55.866158800Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\"),\n",
    "    'attack_success_rate': tf.keras.metrics.Mean(name=\"attack_success_rate\")\n",
    "}\n",
    "def op_with_even_check_tensor(args):\n",
    "    x, y = args\n",
    "    x_even = tf.equal(x % 2, 0)\n",
    "    y_even = tf.equal(y % 2, 0)\n",
    "    both_even = tf.logical_and(x_even, y_even)\n",
    "    result = tf.where(both_even, x + y, minus_one)\n",
    "    return result\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = op_with_even_check_tensor((predictions_x, predictions_y))\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z,is_poisoned_flags, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z =  op_with_even_check_tensor((predictions_x, predictions_y))\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    target_label = 1  # Replace with your actual target label if needed\n",
    "\n",
    "    is_poisoned_flags = tf.cast(is_poisoned_flags, tf.bool)\n",
    "\n",
    "    # Success if either operand predicts target\n",
    "    preds_match_target = tf.logical_or(\n",
    "        tf.equal(predictions_x, target_label),\n",
    "        tf.equal(predictions_y, target_label)\n",
    "    )\n",
    "\n",
    "    # Only consider poisoned inputs\n",
    "    successful_attacks = tf.boolean_mask(preds_match_target, is_poisoned_flags)\n",
    "\n",
    "    # Compute ASR\n",
    "    if tf.size(successful_attacks) > 0:\n",
    "        asr = tf.reduce_mean(tf.cast(successful_attacks, tf.float32))\n",
    "    else:\n",
    "        asr = 0.0\n",
    "\n",
    "    metrics_dict['attack_success_rate'](asr)\n",
    "    # print(\"Poisoned flags:\", is_poisoned_flags)\n",
    "    # print(\"Predictions_x:\", predictions_x)\n",
    "    # print(\"Predictions_y:\", predictions_y)\n",
    "    # print(\"Success:\", successful_attacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:01:55.912394600Z",
     "start_time": "2025-05-28T12:01:55.891951200Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n",
    "for epoch in range(20,30):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(8.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:02:13.045188900Z",
     "start_time": "2025-05-28T12:01:55.897399800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss: 0.9878, train_accuracy: 0.4382, test_loss: 0.9869, test_accuracy: 0.3194, attack_success_rate: 0.0000\n",
      "Epoch 1, train_loss: 0.9869, train_accuracy: 0.3221, test_loss: 0.9870, test_accuracy: 0.3185, attack_success_rate: 0.0000\n",
      "Epoch 2, train_loss: 0.9869, train_accuracy: 0.3211, test_loss: 0.9869, test_accuracy: 0.3194, attack_success_rate: 0.0000\n",
      "Epoch 3, train_loss: 0.9869, train_accuracy: 0.3255, test_loss: 0.9870, test_accuracy: 0.3185, attack_success_rate: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcommons_attacked\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcommons_new\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m history = \u001B[43mcommons_new\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetrics_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetrics_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds_train\u001B[49m\u001B[43m=\u001B[49m\u001B[43mds_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mds_test\u001B[49m\u001B[43m=\u001B[49m\u001B[43mds_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_step\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtest_step\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpoison_indices_test\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43mpoison_indices_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscheduled_parameters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscheduled_parameters\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\logictensornetwork\\examples\\mnist\\commons_attacked.py:36\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(epochs, metrics_dict, ds_train, ds_test, train_step, test_step, poison_indices_test, csv_path, scheduled_parameters)\u001B[39m\n\u001B[32m     34\u001B[39m     images_x, images_y, labels_z, _ = batch_elements\n\u001B[32m     35\u001B[39m     \u001B[38;5;66;03m# train_step(images_x images_y, labels_z,  **scheduled_parameters[epoch])\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m     \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_z\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mscheduled_parameters\u001B[49m\u001B[43m[\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_elements \u001B[38;5;129;01min\u001B[39;00m ds_test:\n\u001B[32m     38\u001B[39m     images_x, images_y, labels_z, is_poisoned_flags = batch_elements\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    866\u001B[39m   \u001B[38;5;28mself\u001B[39m._lock.release()\n\u001B[32m    867\u001B[39m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[32m    868\u001B[39m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m869\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    870\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[32m    871\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    872\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    873\u001B[39m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[32m    874\u001B[39m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[32m    875\u001B[39m   \u001B[38;5;28mself\u001B[39m._lock.release()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[39m, in \u001B[36mcall_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    137\u001B[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001B[32m    138\u001B[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[32m    140\u001B[39m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001B[39m, in \u001B[36mConcreteFunction._call_flat\u001B[39m\u001B[34m(self, tensor_inputs, captured_inputs)\u001B[39m\n\u001B[32m   1318\u001B[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001B[32m   1319\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[32m   1320\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[32m   1321\u001B[39m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1322\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_inference_function\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1323\u001B[39m forward_backward = \u001B[38;5;28mself\u001B[39m._select_forward_and_backward_functions(\n\u001B[32m   1324\u001B[39m     args,\n\u001B[32m   1325\u001B[39m     possible_gradient_type,\n\u001B[32m   1326\u001B[39m     executing_eagerly)\n\u001B[32m   1327\u001B[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001B[39m, in \u001B[36mAtomicFunction.call_preflattened\u001B[39m\u001B[34m(self, args)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core.Tensor]) -> Any:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m   flat_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.function_type.pack_output(flat_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001B[39m, in \u001B[36mAtomicFunction.call_flat\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m record.stop_recording():\n\u001B[32m    250\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._bound_context.executing_eagerly():\n\u001B[32m--> \u001B[39m\u001B[32m251\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_bound_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    253\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    254\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m.\u001B[49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    255\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    256\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    257\u001B[39m     outputs = make_call_op_in_graph(\n\u001B[32m    258\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    259\u001B[39m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[32m    260\u001B[39m         \u001B[38;5;28mself\u001B[39m._bound_context.function_call_options.as_attrs(),\n\u001B[32m    261\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001B[39m, in \u001B[36mContext.call_function\u001B[39m\u001B[34m(self, name, tensor_inputs, num_outputs)\u001B[39m\n\u001B[32m   1686\u001B[39m cancellation_context = cancellation.context()\n\u001B[32m   1687\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1688\u001B[39m   outputs = \u001B[43mexecute\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1689\u001B[39m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mutf-8\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1690\u001B[39m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1691\u001B[39m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1692\u001B[39m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1693\u001B[39m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1694\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1695\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1696\u001B[39m   outputs = execute.execute_with_cancellation(\n\u001B[32m   1697\u001B[39m       name.decode(\u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1698\u001B[39m       num_outputs=num_outputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1702\u001B[39m       cancellation_manager=cancellation_context,\n\u001B[32m   1703\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\NeSy-vs-Backdoors\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[39m, in \u001B[36mquick_execute\u001B[39m\u001B[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[39m\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     52\u001B[39m   ctx.ensure_initialized()\n\u001B[32m---> \u001B[39m\u001B[32m53\u001B[39m   tensors = \u001B[43mpywrap_tfe\u001B[49m\u001B[43m.\u001B[49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m core._NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     56\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "import commons_attacked as commons_new\n",
    "history = commons_new.train(\n",
    "    epochs=30,\n",
    "    metrics_dict=metrics_dict,\n",
    "    ds_train=ds_train,\n",
    "    ds_test=ds_test,\n",
    "    train_step=train_step,\n",
    "    test_step=test_step,\n",
    "    poison_indices_test =poison_indices_test,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T12:02:13.046188700Z",
     "start_time": "2025-05-28T12:02:13.045188900Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history['train_accuracy'])), history['train_accuracy'], label='Train Accuracy')\n",
    "plt.plot(range(len(history['test_accuracy'])), history['test_accuracy'], label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure()\n",
    "plt.plot(range(len(history['train_loss'])), history['train_loss'], label='Train Loss')\n",
    "plt.plot(range(len(history['test_loss'])), history['test_loss'], label='Test Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Model Loss over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-28T12:02:13.046188700Z"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
