{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All experiments LTN Notebook\n",
    "\n",
    "This notebook contains experiments on the MNIST model. It will contain the following experiments:\n",
    "- changing the number of layers, learning rate etc for basic single_digits_addition and comparing results\n",
    "- adding different levels of symbolic knowledge to the single_digits_addition\n",
    "- multiple_digits_addition with more symbolic knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:41.634095500Z",
     "start_time": "2025-05-11T07:43:37.944895800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data\n",
    "import commons_updated as commons\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Digit Addition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X+Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.667619800Z",
     "start_time": "2025-05-11T07:43:41.638095700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEOCAYAAAApP3VyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGd9JREFUeJzt3Q10VOWdx/H/EJIhQF4IkLcSMICAKwVOEWKEslEoEXYpIGt9X2itKAa6kGOp2RXU6jmp2FUKIqnbltSzRSjbApVqXAwmORyTINGIVMkSGiUUEgTNC0GSkNw99+4mZUryDPOSZ96+n3OuYeZ/M/c5N8nf371z7zM2wzAMAQAA0KSfrg0BAACYCB8AAEArwgcAANCK8AEAALQifAAAAK0IHwAAQCvCBwAA0IrwAQAAtCJ8AAAArfqLn+ns7JTTp09LVFSU2Gw2Xw8HCEnmxMfNzc2SnJws/foFxjEKvQMIoL5h9JGXXnrJGDVqlGG3243p06cb5eXl1/R9tbW15nTvLCwsfrCYf486uds3TPQOFhYJmL7RJ2c+du7cKdnZ2ZKXlydpaWmyceNGyczMlKqqKomPj1d+r3nUYpop86W/hPfF8AA4cVna5aC80f33qIMnfcNE7wACp2/YzATi7QGYjWPatGny0ksvdZ8OTUlJkVWrVsnjjz+u/N6mpiaJiYmRDFko/W00EMAXLhvtUiR7pbGxUaKjo7Vs05O+YaJ3AIHTN7z+Zm5bW5tUVFTInDlz/rqRfv2sx6WlpVet39raajWNKxcAocXVvmGidwCBy+vh49y5c9LR0SEJCQkOz5uP6+rqrlo/NzfXOlrpWswjHQChxdW+YaJ3AIHL55ex5+TkWKdoupba2lpfDwlAAKB3AIHL6xecDhs2TMLCwqS+vt7hefNxYmLiVevb7XZrARC6XO0bJnoHELi8fuYjIiJCpk6dKoWFhd3PmReOmY/T09O9vTkAQYC+AYSWPrnV1rxdbunSpXLTTTfJ9OnTrVvmWlpa5Lvf/W5fbA5AEKBvAKGjT8LHXXfdJZ9//rmsX7/eulhsypQpUlBQcNXFZADQhb4BhI4+mefDE9yrD4TmPB+eoncAITzPBwAAgArhAwAAaEX4AAAAWhE+AACAVoQPAACgFeEDAABoRfgAAABaET4AAIBWhA8AAKAV4QMAAGhF+AAAAFoRPgAAgFaEDwAAoBXhAwAAaEX4AAAAWhE+AACAVoQPAACgFeEDAABoRfgAAABaET4AAIBW/fVuDoEi7O/GKevHsoYo6/1i25T1nbf8XFn/p4KVyvoNmxuU9Y6P/0dZBwD4Dmc+AACAVoQPAACgFeEDAABoRfgAAABaET4AAIBWhA8AAKAV4QMAAGjFPB8h6qu3UpX1F8f9p7I+JcLTXx3191d/O09Zr7z9srL+/edXK+vxL7+rrAMITdUv3qysH/vOFmX91h88qqwP+l25W+MKNl4/8/HUU0+JzWZzWCZMmODtzQAIIvQNILT0yZmPG2+8Ud5+++2/bqQ/J1gAqNE3gNDRJ3/dZtNITEzsi5cGEKToG0Do6JMLTo8fPy7JyckyevRoue++++TkyZO9rtva2ipNTU0OC4DQ40rfMNE7gMDl9fCRlpYm+fn5UlBQIFu3bpWamhr55je/Kc3NzT2un5ubKzExMd1LSkqKt4cEwM+52jdM9A4gcHk9fMybN0/uvPNOmTRpkmRmZsobb7whDQ0N8tvf/rbH9XNycqSxsbF7qa2t9faQAPg5V/uGid4BBK4+v6IrNjZWxo0bJ9XV1T3W7Xa7tQDAtfYNE70DCFx9Hj4uXLggJ06ckAceeKCvN4UrNL05Rlkvmdj7EaWpn59PAeNsnpFD/7ZZWR83aYWyPn5VpbJutLcp6/AMfQPu6jdokLJ+4hdjlfXymf+urE/e+kNlPeV3zCHkk7ddHnvsMSkuLpZPP/1U3n33XVm8eLGEhYXJPffc4+1NAQgS9A0gtHj98PbUqVNWwzh//rwMHz5cZs6cKWVlZda/AaAn9A0gtHg9fOzYscPbLwkgyNE3gNDCB8sBAACtCB8AAEArwgcAANCK8AEAALTy78kc4LaB4e3Kej+x9en2152doqzfN6RcWV9QnKWsRx4boKyXZ72grFcvyFPWb9v3iLI+YN8hZR2Ab1Svm6SsH5u1RVmf8/G9ynrKs8zj4Q2c+QAAAFoRPgAAgFaEDwAAoBXhAwAAaEX4AAAAWhE+AACAVoQPAACgFeEDAABoxSRjcMudJzKV9a/mXVTWKwcvVNbHXzyurHc2NyvrsxrWKOu/WrtRWf/Z5s3K+trzy8UZW+mHTtcB4Jrmu25W1o89oJ5E7K4/z1XWB9zxhbLeqaziWnHmAwAAaEX4AAAAWhE+AACAVoQPAACgFeEDAABoRfgAAABaET4AAIBWzPMRoDoyvqGsPzn6V8p6mE2dO1/4YrSyfmlxh7Le2dKirIuzuoeGby1V1tfUrFTWd/2Heh6Qk7cPcjqGUeohAOiB7aaJyvoLuep5PN5rVb/+xW93eDSHELyDMx8AAEArwgcAANCK8AEAALQifAAAAK0IHwAAQCvCBwAA0IrwAQAAtGKejwC1/JXfKeuzBqi/v8PoVNY3H5yjrI87f0gCWUTBe8r6/ce/o6yXfO95p9v45z8sV9aNij85fQ0g1FSvCVfWp9ltyvrEV9Rz+Iz88l23xgUfn/koKSmRBQsWSHJysthsNtmzZ49D3TAMWb9+vSQlJUlkZKTMmTNHjh8/7s0xAwgw9A0AHoWPlpYWmTx5smzZ0vMscxs2bJBNmzZJXl6elJeXy6BBgyQzM1MuXbrk6qYABAn6BgCP3naZN2+etfTEPHrZuHGjPPHEE7Jw4ULruVdffVUSEhKsI5277777qu9pbW21li5NTU2uDgmAn/N23zDRO4DA5dULTmtqaqSurs46ZdolJiZG0tLSpLS05w+6yM3NtdbpWlJSUrw5JAB+zp2+YaJ3AIHLq+HDbCAm84jlSubjrtrfysnJkcbGxu6ltrbWm0MC4Ofc6RsmegcQuHx+t4vdbrcWAHAFvQMIXF4985GYmGh9ra+vd3jefNxVA4Ar0TeA0OPVMx+pqalWsygsLJQpU6Z0XwRmXr2+YsUKb24q6H3xvXRl/VuR6nvVOwz1RB8zPlTPYzHukcCex8NT1R+orx8YOj7S6WtUPTxQWR+nngYkZNA3QkvDA+re9qeMTcr6c+cnKusjnyl3a1zw8/Bx4cIFqa6udrhYrLKyUuLi4mTkyJGyevVqefbZZ+X666+3msq6deuse/sXLVrk7bEDCBD0DQAehY/Dhw/Lrbfe2v04Ozvb+rp06VLJz8+XtWvXWvf0L1++XBoaGmTmzJlSUFAgAwY4mXITQNCibwDwKHxkZGRY9+X3xpy98Mc//rG1AICJvgHgSnywHAAA0IrwAQAAtCJ8AAAArQgfAAAgtGY4DUVhCfFO13noh3uV9eh+6rsAwmzqXNn6R2dj+OttkaFo7PZm9Qo9f9YZACfOT1LX+0uYsp7/x9uU9dTO3j8PCP6DMx8AAEArwgcAANCK8AEAALQifAAAAK0IHwAAQCvCBwAA0IrwAQAAtGKeDx/oTB7udJ0Ho095tI3Utx5U1m/Y/omy3iGhLewv55T1Y+2t2sYCBJL+SYnK+s8Wb1PW/+V0urI++qn3lfXeP74Q/oQzHwAAQCvCBwAA0IrwAQAAtCJ8AAAArQgfAABAK8IHAADQivABAAC0Yp4PH/hiUnSfb2N4UYSy3vHll30+hlD304ydyvorMlrbWABdar6v/r2+PfINZX3NexOU9dTWD90aF/wLZz4AAIBWhA8AAKAV4QMAAGhF+AAAAFoRPgAAgFaEDwAAoBXhAwAAaMU8Hz7w+czLvh4CnOgYMVxZnxBud/oatZdbvTgiwD/Y7Orf/bR/+EhZ//TyRWX9us1uDQvBfuajpKREFixYIMnJyWKz2WTPnj0O9WXLllnPX7ncfvvt3hwzgABD3wDgUfhoaWmRyZMny5YtW3pdx2waZ86c6V5ee+01VzcDIIjQNwB49LbLvHnzrEXFbrdLYmKiqy8NIEjRNwD0+QWnRUVFEh8fL+PHj5cVK1bI+fPne123tbVVmpqaHBYAoceVvmGidwCBy+vhwzx1+uqrr0phYaE899xzUlxcbB3xdHR09Lh+bm6uxMTEdC8pKSneHhIAP+dq3zDRO4DA5fW7Xe6+++7uf3/961+XSZMmyZgxY6yjmtmzZ1+1fk5OjmRnZ3c/No9eaCJAaHG1b5joHUDg6vN5PkaPHi3Dhg2T6urqXt/njY6OdlgAhDZnfcNE7wACV5/P83Hq1CnrvdukpKS+3lTAGJ1a7/FrVLap5woZ/vZnyjozjaid+lfD49c4eznKK2MJRfQN/1Wz/hvK+h9Ter+jyTR23xplfdy777k1LgR5+Lhw4YLD0UhNTY1UVlZKXFyctTz99NOyZMkS66r1EydOyNq1a2Xs2LGSmZnp7bEDCBD0DQAehY/Dhw/Lrbfe2v246z3XpUuXytatW+XIkSPy61//WhoaGqwJhebOnSvPPPOMdYoUQGiibwDwKHxkZGSIYfR+Svqtt95y9SUBBDn6BoAr8cFyAABAK8IHAADQivABAAC0InwAAIDgmucDV0uIbPb4Nc53DFLWL//ltMfbCGZtmTcp62/ctNHJKwx0uo2nyhYq69dLhdPXAPzN+Jk1Hn3/kA/43w448wEAADQjfAAAAK0IHwAAQCvCBwAA0IrwAQAAtCJ8AAAArQgfAABAK2649oHSj8c6X+m6Qh1DCVhh48Yo66czE5T1V7J/pqx/LUw9j0dFW4c4M+o1m9N1gFAz7MOLvh4C/ABnPgAAgFaEDwAAoBXhAwAAaEX4AAAAWhE+AACAVoQPAACgFeEDAABoxTwfPhBbGe58pfnq8t9Hqu+Vf2JZurI+JL9U/FnYDdcr6/P+65Cy/mhsjbMtiCfuejPL6Trj3lKPEQBCFWc+AACAVoQPAACgFeEDAABoRfgAAABaET4AAIBWhA8AAKAV4QMAAGjFPB8+kPTfdU7X+dMP25T1G8MjlPWfrt+qrH9/wgplPfVx9TwgrfOnKeuNqeq5TAYuUO+Dh697R1m/L+qs9KU7T2Qq6ze8eM7pa3R4cTxAoCj4aqCyHl6r/tu57OXxIAjOfOTm5sq0adMkKipK4uPjZdGiRVJVVeWwzqVLlyQrK0uGDh0qgwcPliVLlkh9fb23xw0ggNA7ALgdPoqLi63mUFZWJvv375f29naZO3eutLS0dK+zZs0aef3112XXrl3W+qdPn5Y77rjDlc0ACDL0DgBuv+1SUFDg8Dg/P986iqmoqJBZs2ZJY2Oj/PKXv5Tt27fLbbfdZq2zbds2ueGGG6ymc/PNN7uyOQBBgt4BwGsXnJoNwxQXF2d9NRuJeUQzZ86c7nUmTJggI0eOlNLSnq8haG1tlaamJocFQHCjdwChze3w0dnZKatXr5YZM2bIxIkTrefq6uokIiJCYmNjHdZNSEiwar29FxwTE9O9pKSkuDskAAGA3gHA7fBhvn979OhR2bFjh0cDyMnJsY6Cupba2lqPXg+Af6N3AHDrVtuVK1fKvn37pKSkREaMGNH9fGJiorS1tUlDQ4PDEYx5xbpZ64ndbrcWAMGP3gHA5fBhGIasWrVKdu/eLUVFRZKamupQnzp1qoSHh0thYaF1m5zJvJ3u5MmTkp6ezh7/fx3H/+x0nVWrfqCs73r5RWV9hj1SWf/ogU3K+s5FScr6wsHqeUAG23z7P4WP2tqV9ZWPqffv4D98oKwb7Z+7Na5QRe8IHh/9+WvK+qUk9RxEcpmZPOBi+DBPl5pXo+/du9e6X7/rvVjz/dbIyEjr64MPPijZ2dnWhWTR0dFWwzGbB1erA6GL3gHA7fCxdev/zZqZkZHh8Lx5S9yyZcusf7/44ovSr18/6+jFvBo9MzNTXn75ZVc2AyDI0DsAePS2izMDBgyQLVu2WAsAmOgdAK7EB8sBAACtCB8AAEArwgcAANCK8AEAALQifAAAAP+f4RR9b8Drh5T1tH9crazvzdysrN8Yrp4I6L6os8q6SN9OIna246Ky/q3DDyvryT9V/2oPerdcWXd+bwYQmoaUq3vHorkNyvrPU3uesbaLra7erXEhsHDmAwAAaEX4AAAAWhE+AACAVoQPAACgFeEDAABoRfgAAABaET4AAIBWzPMRoMY9/J6yvnLRD5T1+nsuKesfz8xX1l/48nplPa9ylnhiSNEAZf1rvyj16PUB9I0wG8e0cI7fEgAAoBXhAwAAaEX4AAAAWhE+AACAVoQPAACgFeEDAABoRfgAAABaMc9HkIrcc0hZv26P+vvnyzc82v5Y+cCj7wcQmDqMTl8PAQGAMx8AAEArwgcAANCK8AEAALQifAAAAK0IHwAAQCvCBwAA0IrwAQAA/Heej9zcXPn9738vx44dk8jISLnlllvkueeek/Hjx3evk5GRIcXFxQ7f9/DDD0teXp73Rg0goNA7gsfwvFJlfX6eeo4gm3zo5REh6M98mI0hKytLysrKZP/+/dLe3i5z586VlpYWh/UeeughOXPmTPeyYcMGb48bQAChdwBw+8xHQUGBw+P8/HyJj4+XiooKmTVrVvfzAwcOlMTERFdeGkAQo3cA8No1H42NjdbXuLg4h+d/85vfyLBhw2TixImSk5MjFy9e7PU1WltbpampyWEBENzoHUBoc/uzXTo7O2X16tUyY8YMq1F0uffee2XUqFGSnJwsR44ckR/96EdSVVVlvd/b23vBTz/9tLvDABBg6B0AbIZhGO5844oVK+TNN9+UgwcPyogRI3pd78CBAzJ79myprq6WMWPG9Hj0Yi5dzKOXlJQUyZCF0t8W7s7QAHjostEuRbLXOkMRHR3t1demdwDByZW+4daZj5UrV8q+ffukpKRE2TxMaWlp1tfeGojdbrcWAMGP3gHA5fBhniRZtWqV7N69W4qKiiQ1NdXp91RWVlpfk5KS2ONAiKJ3AHA7fJi3ym3fvl327t0rUVFRUldXZz0fExNj3bt/4sQJqz5//nwZOnSo9b7tmjVrrKvZJ02a5MqmAAQRegcAt6/5sNlsPT6/bds2WbZsmdTW1sr9998vR48ete7fN99/Xbx4sTzxxBPX/L6x+b6t2ZB43xYInms+6B1A8LvcV9d8OMspZsP42xkKAYDeAeBKfLYLAADQivABAAC0InwAAACtCB8AAEArwgcAANCK8AEAALQifAAAAK0IHwAAQCvCBwAA0IrwAQAAtCJ8AAAArQgfAABAK5c+WE7nB1BdlnaRa/68XQDeZP39XcMHwvkTegcQOH3D78JHc3Oz9fWgvOHroQAhz/x7ND+mPhDQO4DA6Rs2w88ObTo7O+X06dMSFRUlNptNmpqarI/brq2tlejoaF8PLyCxDz0TivvPbAtmA0lOTpZ+/QLj3Vl6h3ex/zwXavvQcKFv+N2ZD3PAI0aMuOp58wcXCj+8vsQ+9Eyo7b9AOePRhd7RN9h/ngulfRhzjX0jMA5pAABA0CB8AAAArfw+fNjtdnnyySetr3AP+9Az7L/AxM/NM+w/z7EPA+iCUwAAENz8/swHAAAILoQPAACgFeEDAABoRfgAAABaET4AAIBWfh8+tmzZItddd50MGDBA0tLS5NChQ74ekt8qKSmRBQsWWFPbmtNL79mzx6Fu3ti0fv16SUpKksjISJkzZ44cP37cZ+P1N7m5uTJt2jRreu74+HhZtGiRVFVVOaxz6dIlycrKkqFDh8rgwYNlyZIlUl9f77Mxo2f0jWtH3/AMfSMIw8fOnTslOzvbuk/6/fffl8mTJ0tmZqacPXvW10PzSy0tLdY+MhtvTzZs2CCbNm2SvLw8KS8vl0GDBln70/zDgEhxcbHVIMrKymT//v3S3t4uc+fOtfZrlzVr1sjrr78uu3btstY3P0vkjjvu8Om44Yi+4Rr6hmfoG24y/Nj06dONrKys7scdHR1GcnKykZub69NxBQLzR7t79+7ux52dnUZiYqLx/PPPdz/X0NBg2O1247XXXvPRKP3b2bNnrf1YXFzcvb/Cw8ONXbt2da/zySefWOuUlpb6cKS4En3DffQNz9E3ro3fnvloa2uTiooK6xTflR8cZT4uLS316dgCUU1NjdTV1TnsT/MDgMxT0uzPnjU2Nlpf4+LirK/m76N5VHPlPpwwYYKMHDmSfegn6BveRd9wHX3j2vht+Dh37px0dHRIQkKCw/PmY/OPAa7p2mfsz2v/ePbVq1fLjBkzZOLEidZz5n6KiIiQ2NhYh3XZh/6DvuFd9A3X0DeuXX8X1gVChvke7tGjR+XgwYO+HgqAAEHfCIIzH8OGDZOwsLCrrgg2HycmJvpsXIGqa5+xP51buXKl7Nu3T9555x0ZMWJE9/PmfjJP6zc0NDiszz70H/QN76JvXDv6RpCED/M01dSpU6WwsNDhlJb5OD093adjC0SpqanWL/qV+7Opqcm6ep39+X/M6+3MBrJ79245cOCAtc+uZP4+hoeHO+xD85a6kydPsg/9BH3Du+gbztE33GT4sR07dlhXVefn5xsff/yxsXz5ciM2Ntaoq6vz9dD8UnNzs/HBBx9Yi/mjfeGFF6x/f/bZZ1b9Jz/5ibX/9u7daxw5csRYuHChkZqaanz11Ve+HrpfWLFihRETE2MUFRUZZ86c6V4uXrzYvc4jjzxijBw50jhw4IBx+PBhIz093VrgP+gbrqFveIa+4R6/Dh+mzZs3Wz+0iIgI6xa6srIyXw/Jb73zzjtW8/jbZenSpd23za1bt85ISEiwmvPs2bONqqoqXw/bb/S078xl27Zt3euYDffRRx81hgwZYgwcONBYvHix1WjgX+gb146+4Rn6hnts5n/cPWsCAAAQNNd8AACA4ET4AAAAWhE+AACAVoQPAACgFeEDAABoRfgAAABaET4AAIBWhA8AAKAV4QMAAGhF+AAAAFoRPgAAgOj0v2e20ob8IcGhAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=2,\n",
    "        op=lambda args: args[0]+args[1])\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class SoftmaxDigitModel(tf.keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def call(self, x):\n",
    "        logits = self.base_model(x)\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "def create_Digit_model(layers_sizes=(84,), batch_size=16):\n",
    "    logits_model = baselines.SingleDigit(hidden_dense_sizes=layers_sizes, inputs_as_a_list=True)\n",
    "    softmax_model = SoftmaxDigitModel(logits_model)\n",
    "    Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "    softmax_model([inputs[0]]),\n",
    "    indices=tf.cast(inputs[1], tf.int32), \n",
    "    axis=1,\n",
    "    batch_dims=1\n",
    "))\n",
    "    return Digit, logits_model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.676998Z",
     "start_time": "2025-05-11T07:43:42.671989300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.752591Z",
     "start_time": "2025-05-11T07:43:42.674998500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Digit, logits_model = create_Digit_model()\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic (Predicates, Functions, Axioms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.753596800Z",
     "start_time": "2025-05-11T07:43:42.696146200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training utilities (optimizer, training steps and metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "    \n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(), semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(), semantics=\"exists\")\n",
    "add = ltn.Function.Lambda(lambda inputs: inputs[0]+inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "            images_x = ltn.Variable(\"x\", images_x)\n",
    "            images_y = ltn.Variable(\"y\", images_y)\n",
    "            labels_z = ltn.Variable(\"z\", labels_z)\n",
    "            axiom = Forall(\n",
    "                ltn.diag(images_x, images_y, labels_z),\n",
    "                Exists(\n",
    "                    (d1, d2),\n",
    "                    And(Digit([images_x, d1]), Digit([images_y, d2])),\n",
    "                    mask=equals([add([d1, d2]), labels_z]),\n",
    "                    p=p_schedule\n",
    "                ),\n",
    "                p=2\n",
    "            )\n",
    "            return axiom.tensor\n",
    "def make_steps(Digit, logits_model):\n",
    "\n",
    "    def train_step(images_x, images_y, labels_z, optimizer, metrics_dict, **parameters):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = 1. - axioms(images_x, images_y, labels_z, **parameters)\n",
    "        gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "        metrics_dict['train_loss'](loss)\n",
    "        predictions_x = tf.argmax(logits_model([images_x]), axis=-1)\n",
    "        predictions_y = tf.argmax(logits_model([images_y]), axis=-1)\n",
    "        predictions_z = predictions_x + predictions_y\n",
    "        match = tf.equal(predictions_z, tf.cast(labels_z, predictions_z.dtype))\n",
    "        metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match, tf.float32)))\n",
    "\n",
    "    def test_step(images_x, images_y, labels_z, metrics_dict, **parameters):\n",
    "        loss = 1. - axioms(images_x, images_y, labels_z, **parameters)\n",
    "        metrics_dict['test_loss'](loss)\n",
    "        predictions_x = tf.argmax(logits_model([images_x]), axis=-1)\n",
    "        predictions_y = tf.argmax(logits_model([images_y]), axis=-1)\n",
    "        predictions_z = predictions_x + predictions_y\n",
    "        match = tf.equal(predictions_z, tf.cast(labels_z, predictions_z.dtype))\n",
    "        metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match, tf.float32)))\n",
    "    \n",
    "    return axioms, train_step, test_step\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.754592900Z",
     "start_time": "2025-05-11T07:43:42.699671900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.781620300Z",
     "start_time": "2025-05-11T07:43:42.716043Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_optimizer(learning_rate=0.001): \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "    }\n",
    "    return optimizer, metrics_dict #check metrics dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.782620400Z",
     "start_time": "2025-05-11T07:43:42.721560900Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_scheduled_parameters():\n",
    "    scheduled_parameters = defaultdict(lambda: {})\n",
    "    for epoch in range(0,4):\n",
    "        scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "    for epoch in range(4,8):\n",
    "        scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "    for epoch in range(8,12):\n",
    "        scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "    for epoch in range(12,20):\n",
    "        scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n",
    "    for epoch in range(20,30):\n",
    "        scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(8.)}\n",
    "    return scheduled_parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Wrapper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def run_experiment(name, Digit, logits_model, learning_rate=0.001, max_epochs=20):\n",
    "    print(f\"Running experiment: {name}\")\n",
    "    optimizer, metrics_dict = create_optimizer(learning_rate)\n",
    "    scheduled_parameters = get_scheduled_parameters()\n",
    "    axioms, train_step, test_step = make_steps(Digit, logits_model)\n",
    "    history = commons.train(\n",
    "        epochs=max_epochs,\n",
    "        optimizer=optimizer,\n",
    "        metrics_dict=metrics_dict,\n",
    "        ds_train=ds_train,\n",
    "        ds_test=ds_test,\n",
    "        train_step=train_step,\n",
    "        test_step=test_step,\n",
    "        scheduled_parameters=scheduled_parameters\n",
    "    )\n",
    "    return name, history, logits_model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T07:43:42.782620400Z",
     "start_time": "2025-05-11T07:43:42.725297Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run multiple experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: baseline\n",
      "Epoch 0, train_loss: 0.9271, train_accuracy: 0.4382, test_loss: 0.8703, test_accuracy: 0.7192\n",
      "Epoch 1, train_loss: 0.8519, train_accuracy: 0.8690, test_loss: 0.8498, test_accuracy: 0.8244\n",
      "Epoch 2, train_loss: 0.8429, train_accuracy: 0.9082, test_loss: 0.8426, test_accuracy: 0.8671\n",
      "Epoch 3, train_loss: 0.8383, train_accuracy: 0.9279, test_loss: 0.8388, test_accuracy: 0.8869\n",
      "Epoch 4, train_loss: 0.6396, train_accuracy: 0.9302, test_loss: 0.6496, test_accuracy: 0.8790\n",
      "Epoch 5, train_loss: 0.6303, train_accuracy: 0.9438, test_loss: 0.6406, test_accuracy: 0.9008\n",
      "Epoch 6, train_loss: 0.6247, train_accuracy: 0.9511, test_loss: 0.6461, test_accuracy: 0.8859\n",
      "Epoch 7, train_loss: 0.6227, train_accuracy: 0.9545, test_loss: 0.6432, test_accuracy: 0.8938\n",
      "Epoch 8, train_loss: 0.4299, train_accuracy: 0.9518, test_loss: 0.4918, test_accuracy: 0.8661\n",
      "Epoch 9, train_loss: 0.4198, train_accuracy: 0.9588, test_loss: 0.4486, test_accuracy: 0.9117\n",
      "Epoch 10, train_loss: 0.4158, train_accuracy: 0.9631, test_loss: 0.4591, test_accuracy: 0.8978\n",
      "Epoch 11, train_loss: 0.4038, train_accuracy: 0.9711, test_loss: 0.4486, test_accuracy: 0.9137\n",
      "Epoch 12, train_loss: 0.3163, train_accuracy: 0.9714, test_loss: 0.4141, test_accuracy: 0.8730\n",
      "Epoch 13, train_loss: 0.3205, train_accuracy: 0.9684, test_loss: 0.3682, test_accuracy: 0.9226\n",
      "Epoch 14, train_loss: 0.3047, train_accuracy: 0.9761, test_loss: 0.3644, test_accuracy: 0.9206\n",
      "Epoch 15, train_loss: 0.3097, train_accuracy: 0.9741, test_loss: 0.3638, test_accuracy: 0.9236\n",
      "Epoch 16, train_loss: 0.3046, train_accuracy: 0.9774, test_loss: 0.3673, test_accuracy: 0.9167\n",
      "Epoch 17, train_loss: 0.3045, train_accuracy: 0.9761, test_loss: 0.3813, test_accuracy: 0.9048\n",
      "Epoch 18, train_loss: 0.3061, train_accuracy: 0.9741, test_loss: 0.3605, test_accuracy: 0.9256\n",
      "Epoch 19, train_loss: 0.3059, train_accuracy: 0.9757, test_loss: 0.3739, test_accuracy: 0.9117\n",
      "Running experiment: deep_net\n",
      "Epoch 0, train_loss: 0.9166, train_accuracy: 0.5143, test_loss: 0.8642, test_accuracy: 0.7450\n",
      "Epoch 1, train_loss: 0.8522, train_accuracy: 0.8670, test_loss: 0.8495, test_accuracy: 0.8204\n",
      "Epoch 2, train_loss: 0.8455, train_accuracy: 0.8900, test_loss: 0.8474, test_accuracy: 0.8353\n",
      "Epoch 3, train_loss: 0.8410, train_accuracy: 0.9089, test_loss: 0.8440, test_accuracy: 0.8502\n",
      "Epoch 4, train_loss: 0.6525, train_accuracy: 0.9059, test_loss: 0.6587, test_accuracy: 0.8611\n",
      "Epoch 5, train_loss: 0.6528, train_accuracy: 0.9039, test_loss: 0.6645, test_accuracy: 0.8433\n",
      "Epoch 6, train_loss: 0.6394, train_accuracy: 0.9229, test_loss: 0.6471, test_accuracy: 0.8839\n",
      "Epoch 7, train_loss: 0.6330, train_accuracy: 0.9362, test_loss: 0.6486, test_accuracy: 0.8819\n",
      "Epoch 8, train_loss: 0.4720, train_accuracy: 0.9066, test_loss: 0.4822, test_accuracy: 0.8720\n",
      "Epoch 9, train_loss: 0.4565, train_accuracy: 0.9192, test_loss: 0.4748, test_accuracy: 0.8810\n",
      "Epoch 10, train_loss: 0.4365, train_accuracy: 0.9392, test_loss: 0.4710, test_accuracy: 0.8889\n",
      "Epoch 11, train_loss: 0.4294, train_accuracy: 0.9461, test_loss: 0.4839, test_accuracy: 0.8790\n",
      "Epoch 12, train_loss: 0.3603, train_accuracy: 0.9358, test_loss: 0.4793, test_accuracy: 0.8135\n",
      "Epoch 13, train_loss: 0.3651, train_accuracy: 0.9342, test_loss: 0.3987, test_accuracy: 0.8948\n",
      "Epoch 14, train_loss: 0.3635, train_accuracy: 0.9325, test_loss: 0.4021, test_accuracy: 0.8869\n",
      "Epoch 15, train_loss: 0.3462, train_accuracy: 0.9465, test_loss: 0.4016, test_accuracy: 0.8929\n",
      "Epoch 16, train_loss: 0.3451, train_accuracy: 0.9445, test_loss: 0.4101, test_accuracy: 0.8829\n",
      "Epoch 17, train_loss: 0.3457, train_accuracy: 0.9448, test_loss: 0.4126, test_accuracy: 0.8790\n",
      "Epoch 18, train_loss: 0.3408, train_accuracy: 0.9511, test_loss: 0.3988, test_accuracy: 0.8938\n",
      "Epoch 19, train_loss: 0.3492, train_accuracy: 0.9451, test_loss: 0.3851, test_accuracy: 0.9097\n",
      "Running experiment: shallow_net\n",
      "Epoch 0, train_loss: 0.9911, train_accuracy: 0.0322, test_loss: 0.9924, test_accuracy: 0.0268\n",
      "Epoch 1, train_loss: 0.9910, train_accuracy: 0.0316, test_loss: 0.9924, test_accuracy: 0.0268\n",
      "Epoch 2, train_loss: 0.9910, train_accuracy: 0.0316, test_loss: 0.9924, test_accuracy: 0.0268\n",
      "Epoch 3, train_loss: 0.9909, train_accuracy: 0.0319, test_loss: 0.9926, test_accuracy: 0.0258\n",
      "Epoch 4, train_loss: 0.9866, train_accuracy: 0.0316, test_loss: 0.9891, test_accuracy: 0.0258\n",
      "Epoch 5, train_loss: 0.9864, train_accuracy: 0.0322, test_loss: 0.9890, test_accuracy: 0.0258\n",
      "Epoch 6, train_loss: 0.9867, train_accuracy: 0.0316, test_loss: 0.9891, test_accuracy: 0.0258\n",
      "Epoch 7, train_loss: 0.9867, train_accuracy: 0.0316, test_loss: 0.9891, test_accuracy: 0.0258\n",
      "Epoch 8, train_loss: 0.9847, train_accuracy: 0.0316, test_loss: 0.9875, test_accuracy: 0.0258\n",
      "Epoch 9, train_loss: 0.9846, train_accuracy: 0.0316, test_loss: 0.9870, test_accuracy: 0.0268\n",
      "Epoch 10, train_loss: 0.9845, train_accuracy: 0.0319, test_loss: 0.9870, test_accuracy: 0.0268\n",
      "Epoch 11, train_loss: 0.9846, train_accuracy: 0.0316, test_loss: 0.9875, test_accuracy: 0.0258\n",
      "Epoch 12, train_loss: 0.9842, train_accuracy: 0.0316, test_loss: 0.9870, test_accuracy: 0.0258\n",
      "Epoch 13, train_loss: 0.9842, train_accuracy: 0.0316, test_loss: 0.9871, test_accuracy: 0.0258\n",
      "Epoch 14, train_loss: 0.9842, train_accuracy: 0.0316, test_loss: 0.9871, test_accuracy: 0.0258\n",
      "Epoch 15, train_loss: 0.9842, train_accuracy: 0.0316, test_loss: 0.9870, test_accuracy: 0.0258\n",
      "Epoch 16, train_loss: 0.9842, train_accuracy: 0.0316, test_loss: 0.9871, test_accuracy: 0.0258\n",
      "Epoch 17, train_loss: 0.9842, train_accuracy: 0.0316, test_loss: 0.9870, test_accuracy: 0.0258\n",
      "Epoch 18, train_loss: 0.9841, train_accuracy: 0.0316, test_loss: 0.9865, test_accuracy: 0.0268\n",
      "Epoch 19, train_loss: 0.9840, train_accuracy: 0.0319, test_loss: 0.9871, test_accuracy: 0.0258\n"
     ]
    }
   ],
   "source": [
    "experiments = [\n",
    "    {\"name\": \"baseline\", \"layer_sizes\": (84,), \"learning_rate\": 0.001},\n",
    "    {\"name\": \"deep_net\", \"layer_sizes\": (128, 64), \"learning_rate\": 0.001},\n",
    "    {\"name\": \"shallow_net\", \"layer_sizes\": (32,), \"learning_rate\": 0.005},\n",
    "]\n",
    "\n",
    "results = []\n",
    "for config in experiments:\n",
    "    Digit, logits_model = create_Digit_model(layers_sizes=config[\"layer_sizes\"])\n",
    "    results.append(run_experiment(\n",
    "        name=config[\"name\"],\n",
    "        Digit=Digit,\n",
    "        logits_model=logits_model,\n",
    "        learning_rate=config[\"learning_rate\"]\n",
    "    ))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T08:20:07.601147900Z",
     "start_time": "2025-05-11T07:43:42.731591100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:20:07.613646300Z",
     "start_time": "2025-05-11T08:20:07.609636900Z"
    }
   },
   "outputs": [],
   "source": [
    "# def train_model():\n",
    "#     optimizer, metrics_dict = create_optimizer()\n",
    "#     scheduled_parameters = get_scheduled_parameters()\n",
    "#     history = commons.train(\n",
    "#     epochs=30,\n",
    "#     optimizer = optimizer,\n",
    "#     metrics_dict=metrics_dict,\n",
    "#     ds_train=ds_train,\n",
    "#     ds_test=ds_test,\n",
    "#     train_step=train_step,\n",
    "#     test_step=test_step,\n",
    "#     scheduled_parameters=scheduled_parameters\n",
    "# )\n",
    "#     return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:20:07.622360700Z",
     "start_time": "2025-05-11T08:20:07.614669600Z"
    }
   },
   "outputs": [],
   "source": [
    "# def plot_results(history):\n",
    "#     plt.figure()\n",
    "#     plt.plot(range(len(history['train_accuracy'])), history['train_accuracy'], label='Train Accuracy')\n",
    "#     plt.plot(range(len(history['test_accuracy'])), history['test_accuracy'], label='Test Accuracy')\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Accuracy\")\n",
    "#     plt.title(\"Model Accuracy over Epochs\")\n",
    "#     plt.grid(True)\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     \n",
    "#     # Plot Loss\n",
    "#     plt.figure()\n",
    "#     plt.plot(range(len(history['train_loss'])), history['train_loss'], label='Train Loss')\n",
    "#     plt.plot(range(len(history['test_loss'])), history['test_loss'], label='Test Loss')\n",
    "#     plt.xlabel(\"Epoch\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.title(\"Model Loss over Epochs\")\n",
    "#     plt.grid(True)\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# history = train_model()\n",
    "# plot_results(history)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T08:20:07.632199200Z",
     "start_time": "2025-05-11T08:20:07.622360700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-11T08:20:07.645197100Z",
     "start_time": "2025-05-11T08:20:07.629689500Z"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
