{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Subtraction Problem\n",
    "\n",
    "Consider a task where one needs to learn a classifier $\\mathtt{subtraction(X,Y,N)}$ where $\\mathtt{X}$ and $\\mathtt{Y}$ are images of digits (the MNIST data set will be used), and $\\mathtt{N}$ is a natural number corresponding to the sum of these digits. The classifier should return an estimate of the validity of the subtraction ($0$ is invalid, $1$ is valid). \n",
    "\n",
    "For instance, if $\\mathtt{X}$ is an image of a 0 and $\\mathtt{Y}$ is an image of a 9:\n",
    "- if $\\mathtt{N} = -9$, then the subtraction is valid; \n",
    "- if $\\mathtt{N} = 4$, then the subtraction is not valid. \n",
    "\n",
    "A natural approach is to seek to first 1) learn a single digit classifier, then 2) benefit from knowledge readily available about the properties of subtraction.\n",
    "For instance, suppose that a predicate $\\mathrm{digit}(x,d)$ gives the likelihood of an image $x$ being of digit $d$, one could query with LTN:    \n",
    "$$\n",
    "\\exists d_1,d_2 : d_1-d_2= \\mathtt{N} \\ (\\mathrm{digit}(\\mathtt{X},d_1)\\land \\mathrm{digit}(\\mathtt{Y},d_2))\n",
    "$$\n",
    "and use the satisfaction of this query as the output of $\\mathtt{subtraction(X,Y,N)}$ .\n",
    "\n",
    "\n",
    "The challenge is the following:\n",
    "- We provide, in the data, pairs of images $\\mathtt{X}$, $\\mathtt{Y}$ and the result of the subtraction $\\mathtt{N}$ (final label),\n",
    "- We do **not** provide the intermediate labels, the correct digits for $d_1$, $d_2$.\n",
    "\n",
    "Regardless, it is possible to use the equation above as background knowledge to train $\\mathrm{digit}$ with LTN.\n",
    "In contrast, a standard neural network baseline cannot incorporate such intermediate components as nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:35:12.915304300Z",
     "start_time": "2025-05-06T11:35:09.172113700Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ltn\n",
    "import baselines, data, commons\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Dataset of images for the digits X and Y, and their label Z s.t. X-Y=Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:35:13.826519900Z",
     "start_time": "2025-05-06T11:35:12.917288800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result label is -3\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train, ds_test = data.get_mnist_op_dataset(\n",
    "        count_train=3000,\n",
    "        count_test=1000,\n",
    "        buffer_size=3000,\n",
    "        batch_size=16,\n",
    "        n_operands=2,\n",
    "        op=lambda args: args[0]-args[1])\n",
    "\n",
    "# Visualize one example\n",
    "x, y, z = next(ds_train.as_numpy_iterator())\n",
    "plt.subplot(121)\n",
    "plt.imshow(x[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "print(\"Result label is %i\" % z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:35:13.889890200Z",
     "start_time": "2025-05-06T11:35:13.824519600Z"
    }
   },
   "outputs": [],
   "source": [
    "logits_model = baselines.SingleDigit(inputs_as_a_list=True)\n",
    "@tf.function\n",
    "def digit_softmax_wrapper(x):\n",
    "    return tf.nn.softmax(logits_model(x))\n",
    "\n",
    "class SoftmaxDigitModel(tf.keras.Model):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "    def call(self, x):\n",
    "        logits = self.base_model(x)\n",
    "        return tf.nn.softmax(logits)\n",
    "\n",
    "softmax_model = SoftmaxDigitModel(logits_model)\n",
    "\n",
    "Digit = ltn.Predicate.Lambda(lambda inputs: tf.gather(\n",
    "    softmax_model([inputs[0]]), \n",
    "    indices=tf.cast(inputs[1], tf.int32), \n",
    "    axis=1,\n",
    "    batch_dims=1\n",
    "))\n",
    "\n",
    "d1 = ltn.Variable(\"digits1\", range(10))\n",
    "d2 = ltn.Variable(\"digits2\", range(10))\n",
    "\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(),semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(),semantics=\"exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of `Diag`: when grounding $x$,$y$,$n$ with three sequences of values, the $i$-th examples of each variable are matching. \n",
    "That is, `(images_x[i],images_y[i],labels[i])` is a tuple from our dataset of valid subtractions.\n",
    "Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:35:16.429624700Z",
     "start_time": "2025-05-06T11:35:13.848889100Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     22\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m sat\n\u001B[32m     24\u001B[39m images_x, images_y, labels_z = \u001B[38;5;28mnext\u001B[39m(ds_train.as_numpy_iterator())\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m \u001B[43maxioms\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_z\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    148\u001B[39m filtered_tb = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001B[39m, in \u001B[36mFunction.__call__\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    830\u001B[39m compiler = \u001B[33m\"\u001B[39m\u001B[33mxla\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mnonXla\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    832\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m._jit_compile):\n\u001B[32m--> \u001B[39m\u001B[32m833\u001B[39m   result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    835\u001B[39m new_tracing_count = \u001B[38;5;28mself\u001B[39m.experimental_get_tracing_count()\n\u001B[32m    836\u001B[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:889\u001B[39m, in \u001B[36mFunction._call\u001B[39m\u001B[34m(self, *args, **kwds)\u001B[39m\n\u001B[32m    886\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    887\u001B[39m   \u001B[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001B[39;00m\n\u001B[32m    888\u001B[39m   initializers = []\n\u001B[32m--> \u001B[39m\u001B[32m889\u001B[39m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_initializers_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43minitializers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    890\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    891\u001B[39m   \u001B[38;5;66;03m# At this point we know that the initialization is complete (or less\u001B[39;00m\n\u001B[32m    892\u001B[39m   \u001B[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001B[39;00m\n\u001B[32m    893\u001B[39m   \u001B[38;5;28mself\u001B[39m._lock.release()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001B[39m, in \u001B[36mFunction._initialize\u001B[39m\u001B[34m(self, args, kwds, add_initializers_to)\u001B[39m\n\u001B[32m    691\u001B[39m \u001B[38;5;28mself\u001B[39m._variable_creation_config = \u001B[38;5;28mself\u001B[39m._generate_scoped_tracing_options(\n\u001B[32m    692\u001B[39m     variable_capturing_scope,\n\u001B[32m    693\u001B[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001B[32m    694\u001B[39m )\n\u001B[32m    695\u001B[39m \u001B[38;5;66;03m# Force the definition of the function for these arguments\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m696\u001B[39m \u001B[38;5;28mself\u001B[39m._concrete_variable_creation_fn = \u001B[43mtracing_compilation\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrace_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    697\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[32m    698\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    700\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvalid_creator_scope\u001B[39m(*unused_args, **unused_kwds):\n\u001B[32m    701\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Disables variable creation.\"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001B[39m, in \u001B[36mtrace_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    175\u001B[39m     args = tracing_options.input_signature\n\u001B[32m    176\u001B[39m     kwargs = {}\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m   concrete_function = \u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracing_options.bind_graph_to_function:\n\u001B[32m    183\u001B[39m   concrete_function._garbage_collector.release()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001B[39m, in \u001B[36m_maybe_define_function\u001B[39m\u001B[34m(args, kwargs, tracing_options)\u001B[39m\n\u001B[32m    281\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    282\u001B[39m   target_func_type = lookup_func_type\n\u001B[32m--> \u001B[39m\u001B[32m283\u001B[39m concrete_function = \u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget_func_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookup_func_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    287\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m tracing_options.function_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    288\u001B[39m   tracing_options.function_cache.add(\n\u001B[32m    289\u001B[39m       concrete_function, current_func_context\n\u001B[32m    290\u001B[39m   )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001B[39m, in \u001B[36m_create_concrete_function\u001B[39m\u001B[34m(function_type, type_context, func_graph, tracing_options)\u001B[39m\n\u001B[32m    303\u001B[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001B[32m    304\u001B[39m       placeholder_context\n\u001B[32m    305\u001B[39m   )\n\u001B[32m    307\u001B[39m disable_acd = tracing_options.attributes \u001B[38;5;129;01mand\u001B[39;00m tracing_options.attributes.get(\n\u001B[32m    308\u001B[39m     attributes_lib.DISABLE_ACD, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    309\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m310\u001B[39m traced_func_graph = \u001B[43mfunc_graph_module\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpython_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m    \u001B[49m\u001B[43madd_control_dependencies\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdisable_acd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m    \u001B[49m\u001B[43marg_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunction_type_utils\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_arg_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    322\u001B[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001B[32m    324\u001B[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001B[39m, in \u001B[36mfunc_graph_from_py_func\u001B[39m\u001B[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[39m\n\u001B[32m   1057\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[32m   1059\u001B[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001B[32m-> \u001B[39m\u001B[32m1060\u001B[39m func_outputs = \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1062\u001B[39m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[32m   1063\u001B[39m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[32m   1064\u001B[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001B[39m, in \u001B[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m    595\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m default_graph._variable_creator_scope(scope, priority=\u001B[32m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[32m    596\u001B[39m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[32m    597\u001B[39m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[32m    598\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[32m--> \u001B[39m\u001B[32m599\u001B[39m     out = \u001B[43mweak_wrapped_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43m__wrapped__\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    600\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001B[39m, in \u001B[36mpy_func_from_autograph.<locals>.autograph_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     39\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001B[39;00m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapi\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m      \u001B[49m\u001B[43moriginal_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     44\u001B[39m \u001B[43m      \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconverter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mConversionOptions\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[43m          \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m          \u001B[49m\u001B[43moptional_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m          \u001B[49m\u001B[43muser_requested\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m      \u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[32m     51\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[33m\"\u001B[39m\u001B[33mag_error_metadata\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001B[39m, in \u001B[36mconverted_call\u001B[39m\u001B[34m(f, args, kwargs, caller_fn_scope, options)\u001B[39m\n\u001B[32m    437\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    438\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m439\u001B[39m     result = \u001B[43mconverted_f\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43meffective_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    440\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    441\u001B[39m     result = converted_f(*effective_args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Temp\\__autograph_generated_filezxdlq0yw.py:13\u001B[39m, in \u001B[36mouter_factory.<locals>.inner_factory.<locals>.tf__axioms\u001B[39m\u001B[34m(images_x, images_y, labels_z, p_schedule)\u001B[39m\n\u001B[32m     11\u001B[39m images_y = ag__.converted_call(ag__.ld(ltn).Variable, (\u001B[33m'\u001B[39m\u001B[33my\u001B[39m\u001B[33m'\u001B[39m, ag__.ld(images_y)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[32m     12\u001B[39m labels_z = ag__.converted_call(ag__.ld(ltn).Variable, (\u001B[33m'\u001B[39m\u001B[33mz\u001B[39m\u001B[33m'\u001B[39m, ag__.ld(labels_z)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m axiom = ag__.converted_call(ag__.ld(Forall), (ag__.converted_call(ag__.ld(ltn).diag, (ag__.ld(images_x), ag__.ld(images_y), ag__.ld(labels_z)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope), ag__.converted_call(ag__.ld(Exists), ((ag__.ld(d1), ag__.ld(d2)), ag__.converted_call(ag__.ld(And), (ag__.converted_call(ag__.ld(Digit), ([ag__.ld(images_x), ag__.ld(d1)],), \u001B[38;5;28;01mNone\u001B[39;00m, fscope), ag__.converted_call(ag__.ld(Digit), ([ag__.ld(images_y), ag__.ld(d2)],), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)), \u001B[38;5;28mdict\u001B[39m(mask=ag__.converted_call(ag__.ld(equals), ([\u001B[43mag__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubtract\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mag__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43md1\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[43m.\u001B[49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43md2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m, ag__.ld(labels_z)],), \u001B[38;5;28;01mNone\u001B[39;00m, fscope), p=ag__.ld(p_schedule)), fscope)), \u001B[38;5;28mdict\u001B[39m(p=\u001B[32m2\u001B[39m), fscope)\n\u001B[32m     14\u001B[39m sat = ag__.ld(axiom).tensor\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:427\u001B[39m, in \u001B[36mconverted_call\u001B[39m\u001B[34m(f, args, kwargs, caller_fn_scope, options)\u001B[39m\n\u001B[32m    425\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    426\u001B[39m   program_ctx = converter.ProgramContext(options=options)\n\u001B[32m--> \u001B[39m\u001B[32m427\u001B[39m   converted_f = \u001B[43m_convert_actual\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_entity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogram_ctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    428\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m logging.has_verbosity(\u001B[32m2\u001B[39m):\n\u001B[32m    429\u001B[39m     _log_callargs(converted_f, effective_args, kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:269\u001B[39m, in \u001B[36m_convert_actual\u001B[39m\u001B[34m(entity, program_ctx)\u001B[39m\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(entity, \u001B[33m'\u001B[39m\u001B[33m__code__\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m    265\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mCannot apply autograph to a function that doesn\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[33mt \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    266\u001B[39m                    \u001B[33m'\u001B[39m\u001B[33mexpose a __code__ object. If this is a @tf.function,\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    267\u001B[39m                    \u001B[33m'\u001B[39m\u001B[33m try passing f.python_function instead.\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m269\u001B[39m transformed, module, source_map = \u001B[43m_TRANSPILER\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mentity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogram_ctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformed, \u001B[33m'\u001B[39m\u001B[33mag_module\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    272\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(transformed, \u001B[33m'\u001B[39m\u001B[33mag_source_map\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:282\u001B[39m, in \u001B[36mGenericTranspiler.transform\u001B[39m\u001B[34m(self, obj, user_context)\u001B[39m\n\u001B[32m    267\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Transforms a Python object.\u001B[39;00m\n\u001B[32m    268\u001B[39m \n\u001B[32m    269\u001B[39m \u001B[33;03mUsers typically call this method.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    279\u001B[39m \u001B[33;03m  NotImplementedError: if the type of obj is not handled.\u001B[39;00m\n\u001B[32m    280\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    281\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inspect.isfunction(obj) \u001B[38;5;129;01mor\u001B[39;00m inspect.ismethod(obj):\n\u001B[32m--> \u001B[39m\u001B[32m282\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransform_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_context\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[33m'\u001B[39m\u001B[33mNon-function: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m'\u001B[39m.format(\u001B[38;5;28mtype\u001B[39m(obj)))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:487\u001B[39m, in \u001B[36mPyToPy.transform_function\u001B[39m\u001B[34m(self, fn, user_context)\u001B[39m\n\u001B[32m    483\u001B[39m         logging.log(\u001B[32m2\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mTransformed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m'\u001B[39m, fn, parser.unparse(nodes))\n\u001B[32m    485\u001B[39m       factory = _PythonFnFactory(\n\u001B[32m    486\u001B[39m           ctx.info.name, fn.\u001B[34m__code__\u001B[39m.co_freevars, \u001B[38;5;28mself\u001B[39m.get_extra_locals())\n\u001B[32m--> \u001B[39m\u001B[32m487\u001B[39m       \u001B[43mfactory\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    488\u001B[39m \u001B[43m          \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnamer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfuture_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mctx\u001B[49m\u001B[43m.\u001B[49m\u001B[43minfo\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfuture_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    489\u001B[39m       \u001B[38;5;28mself\u001B[39m._cache[fn][cache_subkey] = factory\n\u001B[32m    491\u001B[39m transformed_fn = factory.instantiate(\n\u001B[32m    492\u001B[39m     globals_=fn.\u001B[34m__globals__\u001B[39m,\n\u001B[32m    493\u001B[39m     closure=fn.\u001B[34m__closure__\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (),\n\u001B[32m    494\u001B[39m     defaults=fn.\u001B[34m__defaults__\u001B[39m,\n\u001B[32m    495\u001B[39m     kwdefaults=\u001B[38;5;28mgetattr\u001B[39m(fn, \u001B[33m'\u001B[39m\u001B[33m__kwdefaults__\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\transpiler.py:179\u001B[39m, in \u001B[36m_PythonFnFactory.create\u001B[39m\u001B[34m(self, nodes, namer, inner_factory_name, outer_factory_name, future_features)\u001B[39m\n\u001B[32m    174\u001B[39m outer_factory_name = namer.new_symbol(outer_factory_name, ())\n\u001B[32m    175\u001B[39m nodes = _wrap_into_factory(nodes, \u001B[38;5;28mself\u001B[39m._name, inner_factory_name,\n\u001B[32m    176\u001B[39m                            outer_factory_name, \u001B[38;5;28mself\u001B[39m._freevars,\n\u001B[32m    177\u001B[39m                            \u001B[38;5;28mself\u001B[39m._extra_locals.keys(), future_features)\n\u001B[32m--> \u001B[39m\u001B[32m179\u001B[39m module, _, source_map = \u001B[43mloader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_ast\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_source_map\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    181\u001B[39m outer_factory = \u001B[38;5;28mgetattr\u001B[39m(module, outer_factory_name)\n\u001B[32m    182\u001B[39m \u001B[38;5;28mself\u001B[39m._unbound_factory = outer_factory()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\loader.py:94\u001B[39m, in \u001B[36mload_ast\u001B[39m\u001B[34m(nodes, indentation, include_source_map, delete_on_exit)\u001B[39m\n\u001B[32m     91\u001B[39m   nodes = (nodes,)\n\u001B[32m     93\u001B[39m source = parser.unparse(nodes, indentation=indentation)\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m module, _ = \u001B[43mload_source\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelete_on_exit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m include_source_map:\n\u001B[32m     97\u001B[39m   source_map = origin_info.create_source_map(nodes, source, module.\u001B[34m__file__\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\Delft\\Y3\\research_project\\.venv\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\loader.py:61\u001B[39m, in \u001B[36mload_source\u001B[39m\u001B[34m(source, delete_on_exit)\u001B[39m\n\u001B[32m     59\u001B[39m spec = importlib.util.spec_from_file_location(module_name, file_name)\n\u001B[32m     60\u001B[39m module = importlib.util.module_from_spec(spec)\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m \u001B[43mspec\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexec_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# TODO(mdan): Use our own garbage-collected cache instead of sys.modules.\u001B[39;00m\n\u001B[32m     63\u001B[39m sys.modules[module_name] = module\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:990\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:1141\u001B[39m, in \u001B[36mget_code\u001B[39m\u001B[34m(self, fullname)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:1208\u001B[39m, in \u001B[36m_cache_bytecode\u001B[39m\u001B[34m(self, source_path, bytecode_path, data)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:625\u001B[39m, in \u001B[36m_calc_mode\u001B[39m\u001B[34m(path)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:147\u001B[39m, in \u001B[36m_path_stat\u001B[39m\u001B[34m(path)\u001B[39m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "source": [
    "# mask\n",
    "subtract = ltn.Function.Lambda(lambda inputs: inputs[0]-inputs[1])\n",
    "equals = ltn.Predicate.Lambda(lambda inputs: inputs[0] == inputs[1])\n",
    "\n",
    "### Axioms\n",
    "@tf.function\n",
    "def axioms(images_x, images_y, labels_z, p_schedule=tf.constant(2.)):\n",
    "    images_x = ltn.Variable(\"x\", images_x)\n",
    "    images_y = ltn.Variable(\"y\", images_y)\n",
    "    labels_z = ltn.Variable(\"z\", labels_z)\n",
    "    axiom = Forall(\n",
    "            ltn.diag(images_x,images_y,labels_z),\n",
    "            Exists(\n",
    "                (d1,d2),\n",
    "                And(Digit([images_x,d1]),Digit([images_y,d2])),\n",
    "                mask=equals([subtract([d1,d2]), labels_z]),\n",
    "                p=p_schedule\n",
    "            ),\n",
    "            p=2\n",
    "        )\n",
    "    sat = axiom.tensor\n",
    "    return sat\n",
    "\n",
    "images_x, images_y, labels_z = next(ds_train.as_numpy_iterator())\n",
    "axioms(images_x, images_y, labels_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer, training steps and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:35:16.431625400Z",
     "start_time": "2025-05-06T11:35:16.430625200Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics_dict = {\n",
    "    'train_loss': tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_loss': tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\")    \n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def train_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    gradients = tape.gradient(loss, logits_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, logits_model.trainable_variables))\n",
    "    metrics_dict['train_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x - predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['train_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images_x, images_y, labels_z, **parameters):\n",
    "    # loss\n",
    "    loss = 1.- axioms(images_x, images_y, labels_z, **parameters)\n",
    "    metrics_dict['test_loss'](loss)\n",
    "    # accuracy\n",
    "    predictions_x = tf.argmax(logits_model([images_x]),axis=-1)\n",
    "    predictions_y = tf.argmax(logits_model([images_y]),axis=-1)\n",
    "    predictions_z = predictions_x - predictions_y\n",
    "    match = tf.equal(predictions_z,tf.cast(labels_z,predictions_z.dtype))\n",
    "    metrics_dict['test_accuracy'](tf.reduce_mean(tf.cast(match,tf.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:35:16.431625400Z",
     "start_time": "2025-05-06T11:35:16.431625400Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "scheduled_parameters = defaultdict(lambda: {})\n",
    "for epoch in range(0,4):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(1.)}\n",
    "for epoch in range(4,8):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(2.)}\n",
    "for epoch in range(8,12):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(4.)}\n",
    "for epoch in range(12,20):\n",
    "    scheduled_parameters[epoch] = {\"p_schedule\":tf.constant(6.)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T11:35:16.433625700Z",
     "start_time": "2025-05-06T11:35:16.432625600Z"
    }
   },
   "outputs": [],
   "source": [
    "history = commons.train(\n",
    "    20,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    scheduled_parameters=scheduled_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-06T11:35:16.433625700Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(history['train_accuracy'])), history['train_accuracy'], label='Train Accuracy')\n",
    "plt.plot(range(len(history['test_accuracy'])), history['test_accuracy'], label='Test Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure()\n",
    "plt.plot(range(len(history['train_loss'])), history['train_loss'], label='Train Loss')\n",
    "plt.plot(range(len(history['test_loss'])), history['test_loss'], label='Test Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Model Loss over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12eaedf9b9a64329743e8900a3192e3d75dbaaa78715534825922e4a4f7d9137"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
